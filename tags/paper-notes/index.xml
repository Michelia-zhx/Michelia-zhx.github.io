<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Paper Notes on Michelia&#39;Log</title>
    <link>https://michelia-zhx.github.io/tags/paper-notes/</link>
    <description>Recent content in Paper Notes on Michelia&#39;Log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language><atom:link href="https://michelia-zhx.github.io/tags/paper-notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Paper Notes - Active Learning</title>
      <link>https://michelia-zhx.github.io/posts/2021-08-31-active_learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michelia-zhx.github.io/posts/2021-08-31-active_learning/</guid>
      <description>Active Learning 也称为查询学习或者最优实验设计. 主动学习通过设计合理的查询函数, 不断从未标注的数据中挑选出数据标注后放入训练集. 有效的主动学习数据选择策</description>
    </item>
    
    <item>
      <title>Paper Notes - Multi-Teacher Knowledge Distillation - 1</title>
      <link>https://michelia-zhx.github.io/posts/2022-02-23-multi_teacher_knowledge_distillation-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michelia-zhx.github.io/posts/2022-02-23-multi_teacher_knowledge_distillation-1/</guid>
      <description>Learning from Multiple Teacher Networks http://library.usc.edu.ph/ACM/KKD%202017/pdfs/p1285.pdf loss: teachers的softmax输出取平均和student的交叉熵 中间层表示的相对相异度(仅适用于MTKD), 三元组$(q_i</description>
    </item>
    
    <item>
      <title>Paper Notes - Multi-Teacher Knowledge Distillation - 2</title>
      <link>https://michelia-zhx.github.io/posts/2022-02-24-multi_teacher_knowledge_distillation-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michelia-zhx.github.io/posts/2022-02-24-multi_teacher_knowledge_distillation-2/</guid>
      <description>Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks https://arxiv.org/pdf/2004.05937.pdf Learning from Multiple Teacher Networks, KDD 2017 Efficient knowledge distillation from an ensemble of teachers. Interspeech 2017: 对teacher的logits取加权平均, 加权平均和student的logit</description>
    </item>
    
    <item>
      <title>Paper Notes - Object Detection</title>
      <link>https://michelia-zhx.github.io/posts/2021-09-12-object_detection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michelia-zhx.github.io/posts/2021-09-12-object_detection/</guid>
      <description>Definition Image Classification: 输入图片, 输出图中目标物体的类别. Object Localization: 输入图片, 输出图中物体的 bounding box. Object Detection: 输入图片, 输出图中物体的 bounding box 和类别. R-CNN Model Family 采用region proposal methods, 首</description>
    </item>
    
    <item>
      <title>Paper Notes - Self-Supervised Learning</title>
      <link>https://michelia-zhx.github.io/posts/2021-09-05-self_supervised_learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michelia-zhx.github.io/posts/2021-09-05-self_supervised_learning/</guid>
      <description>Why self-supervised learning: 主要的问题在于获取数据及其标注部分. Definition: Self-supervised learning is a method that poses the following question to formulate an unsupervised learning problem as a supervised one: &amp;ldquo;Can we design the task in such a way that we can generate virtually unlimited labels from our existing images and use that to learn the representations?&amp;rdquo; Replace</description>
    </item>
    
    <item>
      <title>Paper Notes - Vision Transformer</title>
      <link>https://michelia-zhx.github.io/posts/2022-04-02-vit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michelia-zhx.github.io/posts/2022-04-02-vit/</guid>
      <description>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale 在整体的实现上, 原文完全使用原始bert的transformer结构, 主要是对图片转换成类似token的处理, 原文引</description>
    </item>
    
    <item>
      <title>Paper Notes - Week 1</title>
      <link>https://michelia-zhx.github.io/posts/2021-07-15-pros_paper_notes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michelia-zhx.github.io/posts/2021-07-15-pros_paper_notes/</guid>
      <description>Mining Typhoon Knowledge with Neural Networks &amp;ndash; Zhi-Hua Zhou, Shi-Fu Chen, Zhao-Qian Chen - 1999 需解决的问题: 神经网络的两个缺点 &amp;ndash; 数据量大, 训练时间长; 神经网络对知识的学习果不能直接用于决策. Fast neural model - FTART (Firld Theory</description>
    </item>
    
    <item>
      <title>Paper Notes - Week 2</title>
      <link>https://michelia-zhx.github.io/posts/2021-07-22-pros_paper_notes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michelia-zhx.github.io/posts/2021-07-22-pros_paper_notes/</guid>
      <description>Multi-Instance Multi-Label Learning with Application to Scene Classification &amp;ndash; Zhi-Hua Zhou, Min-Ling Zhang, NIPS 2006 Multi-instance: 一个example包含多个instance, example只对应1个label; Multi-label: 一个example对应多个</description>
    </item>
    
  </channel>
</rss>
