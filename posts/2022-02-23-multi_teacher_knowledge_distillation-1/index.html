<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Paper Notes - Multi-Teacher Knowledge Distillation - 1 | Michelia&#39;Log</title>
<meta name="keywords" content="Hugo, static, generator" />
<meta name="description" content="Learning from Multiple Teacher Networks http://library.usc.edu.ph/ACM/KKD%202017/pdfs/p1285.pdf loss: teachersçš„softmaxè¾“å‡ºå–å¹³å‡å’Œstudentçš„äº¤å‰ç†µ ä¸­é—´å±‚è¡¨ç¤ºçš„ç›¸å¯¹ç›¸å¼‚åº¦(ä»…é€‚ç”¨äºMTKD), ä¸‰å…ƒç»„$(q_i">
<meta name="author" content="Michelia-zhx">
<link rel="canonical" href="https://michelia-zhx.github.io/posts/2022-02-23-multi_teacher_knowledge_distillation-1/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.4bcc1deda0e644393cb3bd3d41e049ce42f56b7a20b296422238fe37ee023d76.css" integrity="sha256-S8wd7aDmRDk8s709QeBJzkL1a3ogspZCIjj&#43;N&#43;4CPXY=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://michelia-zhx.github.io/images/Cheese.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://michelia-zhx.github.io/images/Cheese.ico">
<link rel="icon" type="image/png" sizes="32x32" href="https://michelia-zhx.github.io/images/Cheese.ico">
<link rel="apple-touch-icon" href="https://michelia-zhx.github.io/images/Cheese.ico">
<link rel="mask-icon" href="https://michelia-zhx.github.io/images/Cheese.ico">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Paper Notes - Multi-Teacher Knowledge Distillation - 1" />
<meta property="og:description" content="Learning from Multiple Teacher Networks http://library.usc.edu.ph/ACM/KKD%202017/pdfs/p1285.pdf loss: teachersçš„softmaxè¾“å‡ºå–å¹³å‡å’Œstudentçš„äº¤å‰ç†µ ä¸­é—´å±‚è¡¨ç¤ºçš„ç›¸å¯¹ç›¸å¼‚åº¦(ä»…é€‚ç”¨äºMTKD), ä¸‰å…ƒç»„$(q_i" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://michelia-zhx.github.io/posts/2022-02-23-multi_teacher_knowledge_distillation-1/" /><meta property="article:section" content="posts" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Paper Notes - Multi-Teacher Knowledge Distillation - 1"/>
<meta name="twitter:description" content="Learning from Multiple Teacher Networks http://library.usc.edu.ph/ACM/KKD%202017/pdfs/p1285.pdf loss: teachersçš„softmaxè¾“å‡ºå–å¹³å‡å’Œstudentçš„äº¤å‰ç†µ ä¸­é—´å±‚è¡¨ç¤ºçš„ç›¸å¯¹ç›¸å¼‚åº¦(ä»…é€‚ç”¨äºMTKD), ä¸‰å…ƒç»„$(q_i"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://michelia-zhx.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Paper Notes - Multi-Teacher Knowledge Distillation - 1",
      "item": "https://michelia-zhx.github.io/posts/2022-02-23-multi_teacher_knowledge_distillation-1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Paper Notes - Multi-Teacher Knowledge Distillation - 1",
  "name": "Paper Notes - Multi-Teacher Knowledge Distillation - 1",
  "description": "Learning from Multiple Teacher Networks http://library.usc.edu.ph/ACM/KKD%202017/pdfs/p1285.pdf loss: teachersçš„softmaxè¾“å‡ºå–å¹³å‡å’Œstudentçš„äº¤å‰ç†µ ä¸­é—´å±‚è¡¨ç¤ºçš„ç›¸å¯¹ç›¸å¼‚åº¦(ä»…é€‚ç”¨äºMTKD), ä¸‰å…ƒç»„$(q_i",
  "keywords": [
    "Hugo", "static", "generator"
  ],
  "articleBody": " Learning from Multiple Teacher Networks http://library.usc.edu.ph/ACM/KKD%202017/pdfs/p1285.pdf\n  loss:  teachersçš„softmaxè¾“å‡ºå–å¹³å‡å’Œstudentçš„äº¤å‰ç†µ ä¸­é—´å±‚è¡¨ç¤ºçš„ç›¸å¯¹ç›¸å¼‚åº¦(ä»…é€‚ç”¨äºMTKD), ä¸‰å…ƒç»„$(q_i,q_i^+,q_i^-)$, å…¶ä¸­$q$æ˜¯ä¸­é—´å±‚çš„è¾“å‡º, ååºå…³ç³»$q_i^+  q_i^-$ç”±ä¸¤è€…å’Œ$q_i$çš„è·ç¦»$d$å†³å®š, å‚æ•°$w_s$å†³å®šé€‰å–å“ªäº›å±‚. åœ¨ä¸åŒteacherä¸­, ä¸­é—´å±‚è¾“å‡ºçš„ååºå…³ç³»å¯èƒ½ä¸åŒ, å› æ­¤ç”¨æŠ•ç¥¨æ³•å†³å®šä¸­é—´å±‚è¾“å‡ºåº”å½“çš„ååºå…³ç³», è®¾è®¡å’Œstudentå¯¹åº”å±‚è¾“å‡ºçš„loss, ä»¥æ­¤é¼“åŠ±studentæ‹¥æœ‰å’Œteacherä¸­é—´å±‚ç±»ä¼¼çš„ç›¸å¯¹ç›¸ä¼¼(ç›¸å¼‚)å…³ç³». studentå’Œgroudtruthçš„äº¤å‰ç†µ   å®éªŒè®¾ç½®: åŸºäºCIFAR-10, CIFAR-100, MNIST, SVHNçš„å®éªŒ  CIFAR-10, æ¯”è¾ƒstudentä¸åŒå±‚æ•°å’Œå‚æ•°é‡(11/250K, 11/862K, 13/1.6M, 19/2.5M)æ—¶çš„è¡¨ç°(compression rate, acceleration rate and classification accuracy)(å’ŒFitnetsæ¯”è¾ƒ) CIFAR-10, studentå‡ä¸º11å±‚, æ¯”è¾ƒå½“studentçš„å‚æ•°ä¸º250Kå’Œ862Kæ—¶, teacheræ•°é‡ä¸º1, 3, 5æ—¶, Teacher, RDL, FitNets, KDå’Œä»–ä»¬çš„å‡†ç¡®ç‡ CIFAR-10, CIFAR-100, æ¯”è¾ƒä¸åŒæ–¹æ³•(Teacher(5å±‚), FitNets, KD, Maxout Networks, Network in Network, Deeply-Supervised Networkså’Œæ­¤æ–¹æ³•(19å±‚))åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡ MNIST, æ¯”è¾ƒä¸åŒæ–¹æ³•(Teacher(4å±‚), FitNets, KD, Maxout Networks, Network in Network, Deeply-Supervised Networkså’Œæ­¤æ–¹æ³•(7å±‚))çš„å‡†ç¡®ç‡ SVHN, æ¯”è¾ƒä¸åŒæ–¹æ³•(Teacher(5å±‚), FitNets, KD, Maxout Networks, Network in Network, Deeply-Supervised Networkså’Œæ­¤æ–¹æ³•(19å±‚))çš„å‡†ç¡®ç‡   @inproceedings{you2017learning, author={You, Shan and Xu, Chang and Xu, Chao and Tao, Dacheng}, booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, title={Learning from multiple teacher networks}, pages={1285â€“1294}, year={2017} }   Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data. ICLR 2017 https://openreview.net/pdf?id=HkwoSDPgg\n  å­¦ä¹ ç®—æ³•åº”å½“ä¿æŠ¤ç”¨æˆ·ç§äººæ•°æ®, ä½†æ¨¡å‹ä¼šè®°ä½æ•°æ®, ä¹Ÿä¼šå—åˆ°æ”»å‡»(black/white box attack). å°†æ ·æœ¬åˆ†æˆnä»½, åˆ†åˆ«è®­ç»ƒteacher model, å°†è¿™äº›teachersèšåˆ:  å¦‚æœå¤§å¤šæ•°teacheræœ‰ç›¸åŒçš„è¾“å‡º, åˆ™è¾“å‡ºä¸ä¾èµ–äºåˆ†åˆ«è®­ç»ƒteacherçš„ä¸ç›¸äº¤é›† å¦‚æœæœ‰æŸä¸¤ç±»ç¥¨æ•°ç›¸è¿‘, åˆ™åˆ†æ­§å¯èƒ½ä¼šæ³„éœ²ç§äººä¿¡æ¯(æˆ‘ä¸ç†è§£) åœ¨æŠ•ç¥¨ä¸­å¼•å…¥éšæœºå™ªå£°   studentæ˜¯åŠç›‘ç£, ä¸€éƒ¨åˆ†æ˜¯åˆ©ç”¨private dataé€šè¿‡teacherå¾—åˆ°çš„label, ä¹‹åä½¿ç”¨æ— æ ‡è®°çš„public data. åˆ©ç”¨GANè®­ç»ƒstudent, discriminatorå¢åŠ 1ç±»(m+ç”±ç”Ÿæˆå™¨ç”Ÿæˆ), è®­ç»ƒååªä½¿ç”¨discriminator. å®éªŒè®¾ç½®:    Dataset Teacher Student Student Public Data testing Data     MNIST 2 conv + 1 relu GANS(6 fc layers) test[:1000] test[1000:]   SVHN 2 conv + 2 relu GANS(7 conv + 2 NIN) test[:1000] test[1000:]   UCI Adult RF(100 trees) RF(100 trees) test[:500] test[500:]   UCI Diabetes RF(100 trees) RF(100 trees) test[:500] test[500:]     @article{Papernot2017SemisupervisedKT, title={Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data}, author={Nicolas Papernot and Mart{'i}n Abadi and {'U}lfar Erlingsson and Ian J. Goodfellow and Kunal Talwar}, journal={arXiv preprint}, pages = {}, year={2016} }   Knowledge Adaptation: Teaching to Adapt. ICLR, 2017 https://openreview.net/pdf?id=rJRhzzKxl\n  teachersçš„domainå’Œstudent $\\mathcal{D}{T_i}, \\mathcal{D}S$ä¸å®Œå…¨ä¸€è‡´, å› æ­¤studentå¯¹teacherçš„ä¿¡ä»»åº¦å–å†³äºä¸¤è€…è¡¨ç¤ºç©ºé—´çš„ç›¸ä¼¼åº¦ $\\mathcal{L} = \\mathcal{H}(\\sum{i=1}sim(\\mathcal{D}{T_i}, \\mathcal{D}S)\\cdot D{T_i}, D_S)$ å®šä¹‰MCD, MCDè¶Šå¤§è¡¨ç¤ºè¶Šè¿œç¦»åˆ†ç±»è¾¹ç•Œ, è¾“å…¥teacherå¾—åˆ°çš„ç»“æœç½®ä¿¡åº¦è¶Šé«˜. å› æ­¤é€‰å–MCDæœ€å¤§(å³ç½®ä¿¡åº¦æœ€é«˜)çš„nä¸ªæ ·æœ¬, åœ¨teacherä¸­å¾—åˆ°çš„ç»“æœä½œä¸ºä¼ªæ ‡è®°ä»¥è®­ç»ƒstudentå¯ä»¥ä½¿æ— ç›‘ç£å­¦ä¹ çš„æ€§èƒ½å¾—åˆ°æå‡. å®éªŒè®¾ç½®: åŸºäºAmazon product reviews sentiment analysis dataset. åŒ…å«Book, DVD, Electronics, Kitchenå››ç±».  æ¯”è¾ƒteacher, ç”±ä»¥ç›¸åŒç±»åˆ«æ ·æœ¬è®­ç»ƒçš„teacherè®­ç»ƒå‡ºæ¥çš„student, ç”±ä»¥æ‰€æœ‰æ ·æœ¬è®­ç»ƒçš„teacherè®­ç»ƒå‡ºæ¥çš„student, ç»“åˆä»¥ä¸Šä¸¤ç§teacherè®­ç»ƒå‡ºæ¥çš„student, ä»¥åŠè®¸å¤šå…¶ä»–æ¨¡å‹(SCL, SFA, SCL-com, SFA-com, SST, IDDIWP, DWHC, DAM, CP-MDA, SDAMS-SVM, SDAMS-Log)åœ¨å››ç§ç±»åˆ«ä¸Šçš„æ€§èƒ½. æ¯”è¾ƒåˆ†åˆ«ä»¥å…¶ä¸­ä¸‰ç±»ä¸ºdomainçš„teacherè®­ç»ƒä»¥ç¬¬å››ç±»ä¸ºdomainçš„student(B$\\rightarrow$D,E$\\rightarrow$D,K$\\rightarrow$Dä¾æ¬¡è½®æ¢)åœ¨ä¸åŒæ–¹æ³•ä¸‹çš„æ€§èƒ½   @article{ruder2017knowledge, title={Knowledge adaptation: Teaching to adapt}, author={Ruder, Sebastian and Ghaffari, Parsa and Breslin, John G}, journal={arXiv preprint arXiv:1702.02052}, pages = {}, year={2017} }   Deep Model Compression: Distilling Knowledge from Noisy Teachers. Sau, Bharat Bhusan et al. arXiv:1610.09650 https://arxiv.org/pdf/1610.09650.pdf\n  åœ¨teacherçš„è¾“å‡º(studentçš„ç›®æ ‡)ä¸ŠåŠ æ‰°åŠ¨, ç­‰ä»·äºåŸºäºå™ªå£°çš„æ­£åˆ™åŒ–. å¯ç”¨äºæ¨¡å‹å‹ç¼©. å®éªŒè®¾ç½®: åŸºäºMNIST, SVHN, CIFAR-10.  MNIST: teacher â€“ a modified network of LeNet([C5(S1P0)@20-MP2(S2)]- [C5(S1P0)@50-MP2(S2)]- FC500- FC10); student â€“ FC800-FC800-FC10 SVHN: Network-in-Network([C5(S1P2)@192]- [C1(S1P0)@160]- [C1(S1P0)@96-MP3(S2)]- D0.5- [C5(S1P2)@192]- [C1(S1P0)@192]- [C1(S1P0)@192- AP3(S2)]- D0.5- [C3(S1P1)@192]- [C1(S1P0)@192]- [C1(S1P0)@10]- AP8(S1)); student: LeNet([C5(S1P2)@32-MP3(S2)]- [C5(S1P2)@64-MP3(S2)]- FC1024-FC10) CIFAR-10: teacher: same as SVHN; student: a modified version of the LeNet([C5(S1P2)@64-MP2(S2)]- [C5(S1P2)@128- MP2(S2)]-FC1024-FC10).   @article{sau2016deep, title={Deep model compression: Distilling knowledge from noisy teachers}, author={Sau, Bharat Bhusan and Balasubramanian, Vineeth N}, journal={CoRR}, pages = {}, year={2016} }   Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. Tarvainen, Antti and Valpola, Harri. NeurIPS 2017 https://papers.nips.cc/paper/2017/file/68053af2923e00204c3ca7c6a3150cf7-Paper.pdf\n  ç®—æ³•:  æ„å»ºä¸€ä¸ªæ™®é€šçš„ç›‘ç£æ¨¡å‹; copyä¸€ä»½ç›‘ç£å­¦ä¹ æ¨¡å‹, åŸæ¨¡å‹å«åšstudent, æ–°çš„å«teacher; æ¯æ­¥ä½¿ç”¨åŒæ ·çš„minibatchè¾“å…¥åˆ°studentä¸teacheræ¨¡å‹ä¸­, ä½†åœ¨è¾“å…¥æ•°æ®å‰åˆ†åˆ«åŠ å…¥éšæœºå¢å¼ºæˆ–è€…å™ªéŸ³; åŠ å…¥studentä¸teacherè¾“å‡ºçš„ä¸€è‡´æ€§æŸå¤±å‡½æ•°; ä¼˜åŒ–å™¨åªæ›´æ–°studentçš„æƒé‡; æ¯æ­¥ä¹‹å, é‡‡ç”¨studentæƒé‡çš„EMAæ›´æ–°teacheræƒé‡;   æ ¸å¿ƒæ€æƒ³æ˜¯: æ¨¡å‹æ—¢å……å½“å­¦ç”Ÿ, åˆå……å½“è€å¸ˆ. ä½œä¸ºè€å¸ˆ, ç”¨æ¥äº§ç”Ÿå­¦ç”Ÿå­¦ä¹ æ—¶çš„ç›®æ ‡; ä½œä¸ºå­¦ç”Ÿ, åˆ™åˆ©ç”¨æ•™å¸ˆæ¨¡å‹äº§ç”Ÿçš„ç›®æ ‡æ¥è¿›è¡Œå­¦ä¹ . è€Œæ•™å¸ˆæ¨¡å‹çš„å‚æ•°æ˜¯ç”±å†å²ä¸Š(å‰å‡ ä¸ªstep)å‡ ä¸ªå­¦ç”Ÿæ¨¡å‹çš„å‚æ•°ç»è¿‡åŠ æƒå¹³å‡å¾—åˆ°. å¯ä»¥çœ‹æˆæ˜¯ĞŸ-modelä¸­çš„ä¸¤æ¬¡è®¡ç®—ä¸­æ¨¡å‹æ¢æˆäº†ä¸¤ä¸ªä¸åŒçš„æ¨¡å‹, ä¸€ä¸ªå«teacher, ä¸€ä¸ªå«student; å¦å¤–, ä¹Ÿå¯ä»¥çœ‹æˆä½œTemporal ensemblingçš„æ”¹è¿›ç‰ˆ, åœ¨Temporal ensemblingä¸­, é‡‡ç”¨çš„æ˜¯æ¯epochçš„æŒ‡æ•°ç§»åŠ¨å¹³å‡å€¼æ¥èšåˆå†å²æ•°å†…å®¹, è€ŒMean teacheråˆ™æ˜¯åœ¨æ¯è®­ç»ƒæ­¥è¿›è¡Œå¯¹Studentçš„æƒé‡è¿›æŒ‡æ•°ç§»åŠ¨å¹³å‡. å®éªŒè®¾ç½®: åŸºäºSVHNå’ŒCIFAR-10  All the methods in the comparison use a similar 13-layer ConvNet architecture.   @inproceedings{10.5555/3294771.3294885, title = {Mean Teachers Are Better Role Models: Weight-Averaged Consistency Targets Improve Semi-Supervised Deep Learning Results}, author = {Tarvainen, Antti and Valpola, Harri}, booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems}, pages = {1195â€“1204}, year = {2017} }   Born-Again Neural Networks. Furlanello, Tommaso et al. ICML 2018 https://proceedings.mlr.press/v80/furlanello18a/furlanello18a.pdf\n  åŸºäºæ–°æ¨¡å‹çš„è¾“å…¥å’ŒåŸæ¨¡å‹çš„è¾“å…¥é—´çš„äº¤å‰ç†µ, ä½¿ç”¨KDé¡¹ä¿®æ”¹æ›¿ä»£å’Œæ­£åˆ™åŒ–åŸæ¥çš„loss Selves Born-Again Networksé›†æˆçš„å­¦ä¹ é¡ºåº: $\\mathcal{L}(f(x, \\arg\\min_{\\theta_{k-1}}\\mathcal{L}(f(x, \\theta_{k-1}))),f(x,\\theta_k))$, å°†ä¸Šä¸€ä¸ªstudentå­¦åˆ°çš„çŸ¥è¯†ä½œä¸ºç›‘ç£ä¿¡æ¯, æ•™å¯¼ä¸‹ä¸€ä¸ªå­¦ç”Ÿ. å®éªŒè®¾ç½®:  CIFAR-10: Wide-ResNet with different depth and width (28-1, 28-2, 28-5, 28-10) and DenseNet of different depth and growth factor (112-33, 90-60, 80-80, 80-120) CIFAR-100: ä¸ä¸ŠåŒ.   @inproceedings{Furlanello2018BornAN, title={Born Again Neural Networks}, author={Tommaso Furlanello and ZaKnowledge Adaptation: Teaching to Adaptchary Chase Lipton and Michael Tschannen and Laurent Itti and Anima Anandkumar}, booktitle={ICML}, year={2018} }   Deep Mutual Learning. Zhang, Ying et al. CVPR 2018 https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Deep_Mutual_Learning_CVPR_2018_paper.pdf\n  ä¸¤ä¸ª(å¤šä¸ª?)studentsç›¸äº’å­¦ä¹ , å¯¹äºæ¯ä¸ªstudent, æŸå¤±ä¸ºå’Œgroundtruthçš„äº¤å‰ç†µä»¥åŠç›¸å¯¹äºå¦ä¸€ä¸ªstudentçš„softmaxè¾“å‡ºçš„KLæ•£åº¦: $\\mathcal{L}{\\theta_1} = \\mathcal{L}{C_1} + D_{KL}(p_2|p_1), \\theta_1\\leftarrow\\theta_1+\\gamma_t\\dfrac{\\partial\\mathcal{\\theta_1}}{\\partial\\theta_1}$; $\\mathcal{L}{\\theta_2} = \\mathcal{L}{C_2} + D_{KL}(p_1|p_2), \\theta_2\\leftarrow\\theta_2+\\gamma_t\\dfrac{\\partial\\mathcal{\\theta_2}}{\\partial\\theta_2}$ ä¼˜ç‚¹:  éšç€å­¦ç”Ÿç½‘ç»œçš„å¢åŠ å…¶æ•ˆç‡ä¹Ÿå¾—åˆ°æé«˜ å®ƒå¯ä»¥åº”ç”¨åœ¨å„ç§å„æ ·çš„ç½‘ç»œä¸­, åŒ…æ‹¬å¤§å°ä¸åŒçš„ç½‘ç»œ å³ä½¿æ˜¯éå¸¸å¤§çš„ç½‘ç»œé‡‡ç”¨ç›¸äº’å­¦ä¹ ç­–ç•¥, å…¶æ€§èƒ½ä¹Ÿèƒ½å¤Ÿå¾—åˆ°æå‡   å®éªŒè®¾ç½®:  æ•°æ®é›†: ImageNet, CIFAR-10, CIFAR-100, Market-1501 Networks:    ResNet-32 MobileNet InceptionV1 WRN-28-10     0.5M 3.3M 7.8M 36.5M       @inproceedings{8578552, title = {Deep Mutual Learning}, author = {Y. Zhang and T. Xiang and T. M. Hospedales and H. Lu}, booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages = {4320-4328}, year = {2018} }   Data Distillation: Towards Omni-Supervised Learning. Radosavovic, Ilija et al. CVPR 2018 https://openaccess.thecvf.com/content_cvpr_2018/papers/Radosavovic_Data_Distillation_Towards_CVPR_2018_paper.pdf\n  Model Distillation vs. Data Distillation: å‰è€…ensembleåŒä¸€æ ·æœ¬åœ¨ä¸åŒæ¨¡å‹çš„è¾“å‡º, åè€…ensembleåŒä¸€æ ·æœ¬ç»ä¸åŒè½¬æ¢ååœ¨åŒä¸€æ¨¡å‹çš„è¾“å‡º. æ–¹æ³•:  ç”¨æ‰‹åŠ¨æ ‡æ³¨çš„æ•°æ®è®­ç»ƒæ¨¡å‹A ç”¨æ¨¡å‹Aå»è®­ç»ƒæ•°æ®å¢å¹¿ (æœ¬æ–‡ä¸­ä¸º scaling and horizontal flipping) çš„æœªæ ‡æ³¨æ•°æ® å°†æœªæ ‡æ³¨æ•°æ®çš„é¢„æµ‹ç»“æœé€šè¿‡ ensembling å¤šä¸ªé¢„æµ‹ç»“æœ, è½¬åŒ–ä¸º labels åœ¨æ‰‹åŠ¨æ ‡æ³¨å’Œè‡ªåŠ¨æ ‡æ³¨çš„æ•°æ®é›†é‡æ–°è®­ç»ƒæ¨¡å‹   å®éªŒ: åœ¨COCO Keypoint Detection, Object Detection éªŒè¯. teacherå’Œstudentéƒ½æ˜¯Mask R-CNN keypoint detection variant @inproceedings{inproceedings, title = {Data Distillation: Towards Omni-Supervised Learning}, author = {Radosavovic, Ilija and Dollar, Piotr and Girshick, Ross and Gkioxari, Georgia and He, Kaiming}, year = {2018}, doi = {10.1109/CVPR.2018.00433} pages = {4119-4128} }   Multilingual Neural Machine Translation with Knowledge Distillation. ICLR 2019 https://openreview.net/pdf?id=S1gUsoR9YX\n  æ–¹æ³•å¾ˆç®€å•, å°±æ˜¯å…ˆé’ˆå¯¹æ¯å¯¹è¯­è¨€è®­ç»ƒå•ç‹¬çš„ç¿»è¯‘æ¨¡å‹ä½œä¸ºteacher, å†ç”¨multi-teacher KDè®­ç»ƒstudent, losså°±æ˜¯studentå’Œlabelçš„äº¤å‰ç†µä»¥åŠå’Œteacherçš„softmaxè¾“å‡ºçš„äº¤å‰ç†µ. å®éªŒè®¾ç½®: æ•°æ®é›†: IWSLT, WMT, Ted Talk; studentå’Œteacherå‡ä½¿ç”¨Transformer    Task model hidden size $d_{model}$ feed-forward hidden size $d_{ff}$ number of layer     IWSLT and Ted talk tasks 256 1024 2   WMT task 512 2048 6     @article{Tan2019MultilingualNM, title={Multilingual Neural Machine Translation with Knowledge Distillation}, author={Xu Tan and Yi Ren and Di He and Tao Qin and Zhou Zhao and Tie-Yan Liu}, journal={ICLR}, year={2019}, volume={abs/1902.10461} }   Unifying Heterogeneous Classifiers with Distillation. Vongkulbhisal et al. CVPR 2019 https://openaccess.thecvf.com/content_CVPR_2019/papers/Vongkulbhisal_Unifying_Heterogeneous_Classifiers_With_Distillation_CVPR_2019_paper.pdf\n  Nä¸ªä¸åŒçš„æ¨¡å‹$\\mathcal{C} = {C_i}_{i=1}^N$å…·æœ‰ä¸åŒçš„ç»“æ„å’Œç›®æ ‡ç±»åˆ«, $C_i$è¢«è®­ç»ƒä»¥åˆ†åˆ«é¢„æµ‹$p_i(Y=l_j)$, å¹¶æ•´åˆå‡ºæ ·æœ¬åœ¨æ‰€æœ‰ç±»ä¸­çš„æ¦‚ç‡$q(Y=i_j)$. æœ€ååˆ©ç”¨$q$è®­ç»ƒstudent. ä½œè€…æå‡ºäº†åŸºäºäº¤å‰ç†µæœ€å°åŒ–å’ŒçŸ©é˜µåˆ†è§£çš„æ–¹æ³•ï¼Œä»æœªæ ‡è®°çš„æ ·æœ¬ä¸­ä¼°è®¡æ‰€æœ‰ç±»åˆ«çš„soft-labels. å®éªŒè®¾ç½®:  æ•°æ®é›†: ImageNet, LSUN, Places365 $C_i$ä»AlexNet, VGG16, ResNet18, ResNet34ä¸­éšæœºé€‰æ‹©   @article{Vongkulbhisal2019UnifyingHC, title={Unifying Heterogeneous Classifiers With Distillation}, author={Jayakorn Vongkulbhisal and Phongtharin Vinayavekhin and Marco Visentini Scarzanella}, journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, year={2019}, pages={3170-3179} }   Distilled Person Re-Identification: Towards a More Scalable System. Wu, Ancong et al. CVPR 2019 https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_Distilled_Person_Re-Identification_Towards_a_More_Scalable_System_CVPR_2019_paper.pdf\n  è§£å†³ä¸‰ä¸ªé—®é¢˜: é™ä½æ ‡ç­¾æˆæœ¬(å‡å°‘æ ‡ç­¾çš„éœ€æ±‚é‡); é™ä½è·¨æ•°æ®åº“æˆæœ¬(åˆ©ç”¨ä¸€äº›å…ˆéªŒçŸ¥è¯†); é™ä½æµ‹è¯•æˆæœ¬(ä½¿ç”¨è½»é‡çº§ç½‘ç»œ) å‡è®¾taregt domainåŒ…å«10ä¸ªç±»çš„å›¾ç‰‡, å…ˆç”¨å¤šä¸ªä¸ªsource domainåˆ†åˆ«è®­ç»ƒå¤šä¸ªteacher model, source domainä¹‹åå¹¶ä¸ä¼šè¢«ç”¨åˆ°(åˆ©ç”¨ä¸€äº›å…ˆéªŒçŸ¥è¯†â€“é™ä½è·¨æ•°æ®åº“æˆæœ¬); target domainå¯ä»¥åªåŒ…å«10ä¸ªlabelled sample(10ç±»å‡æœ‰), å…¶ä½™å‡ä¸ºunlabeled sample, å¯¹äºNä¸ªunlabelled input, å®šä¹‰ç›¸ä¼¼åº¦çŸ©é˜µ$A$, å…¶ä¸­ç¬¬iè¡Œç¬¬jåˆ—è¡¨ç¤ºç¬¬iä¸ªå›¾åƒå’Œç¬¬jä¸ªå›¾åƒåœ¨åŒä¸€ä¸ªæ¨¡å‹ä¸‹è¾“å‡ºçš„ç›¸ä¼¼åº¦. ä¸ºäº†å°†çŸ¥è¯†ä»teacherè¿ç§»åˆ°student, éœ€è¦æœ€å°åŒ–teacherçš„ç›¸ä¼¼åº¦çŸ©é˜µ$A_T$å’Œstudentçš„ç›¸ä¼¼åº¦çŸ©é˜µ$A_S$çš„è·ç¦»(è¿™å¥è¯æ˜¯å­¦ä¹ single teacher). åˆ†åˆ«åˆ©ç”¨teacherè®¡ç®—target domainä¸­æ¯ä¸€ä¸ªxçš„ç‰¹å¾å‘é‡, å¹¶åˆ†åˆ«è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ$A$, ä½¿ç”¨$L_{ver}$æ›´æ–°æ¯ä¸€ä¸ªè€å¸ˆæ¨¡å‹çš„æƒé‡$a$(å¯ä»¥ç†è§£ä¸ºï¼Œæƒé‡è¶Šå¤§ï¼Œè¯¥è€å¸ˆæ¨¡å‹å¯¹åº”çš„sourceå’Œtargetè¶Šç›¸ä¼¼) è®¡ç®—å‡ºæ¯ä¸€ä¸ªè€å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹å¾—åˆ°çš„ç›¸ä¼¼çŸ©é˜µçš„å·®å¼‚ï¼Œå¹¶ä½¿ç”¨ä¸Šè¿°çš„æƒé‡åŠ æƒï¼Œä»è€Œå¾—åˆ°$L_{ta}$. ä½¿ç”¨$L_{ta}$å¯¹å­¦ç”Ÿæ¨¡å‹è¿›è¡Œæ›´æ–°, å¾ªç¯è®­ç»ƒ. å®éªŒè®¾ç½®: æ•°æ®é›† â€“ Market-1501, DukeMTMC. åˆ†åˆ«ä½¿ç”¨MSMT17, CUHK03, ViPER, DukeMTMC, Market-1501è®­ç»ƒ5ä¸ªteacher model$T_1, T_2, T_3, T_4, T_5$; teacher â€“ an advanced Re-ID model PCB, student â€“ a lightweight mod- el MobileNetV2. @InProceedings{Wu_2019_CVPR, author = {Wu, Ancong and Zheng, Wei-Shi and Guo, Xiaowei and Lai, Jian-Huang}, title = {Distilled Person Re-Identification: Towards a More Scalable System}, booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, month = {June}, year = {2019} }   Diversity with Cooperation: Ensemble Methods for Few-Shot Classification. Dvornik, Nikita et al. ICCV 2019 https://openaccess.thecvf.com/content_ICCV_2019/papers/Dvornik_Diversity_With_Cooperation_Ensemble_Methods_for_Few-Shot_Classification_ICCV_2019_paper.pdf\n  meta learning â€“ learning to learn æ¨¡å‹é—´çš„å…³ç³»æœ‰ä¸‰ç§ - åˆä½œ(é¢„æµ‹çš„ç»“æœæ— è®ºæ˜¯å±äºæ­£ç¡®ç»“æœçš„æ¦‚ç‡è¿˜æ˜¯å±äºé”™è¯¯ç»“æœçš„æ¦‚ç‡éƒ½æ˜¯æ¯”è¾ƒä¸€è‡´çš„), ç‹¬ç«‹(ä¸¤ä¸ªæ¨¡å‹é¢„æµ‹çš„ç»“æœä¹‹é—´ä¸å­˜åœ¨æ˜æ˜¾çš„å…³ç³»), å¤šæ ·æ€§(é™¤äº†æ­£ç¡®ç»“æœï¼Œé¢„æµ‹ä¸ºå…¶ä»–ç»“æœçš„æ¦‚ç‡å·®å¼‚æ˜æ˜¾). æ–‡ç« é€šè¿‡å‡ºäº†äº¤å‰ç†µæŸå¤±å¤–è®¾è®¡ä¸åŒçš„æŸå¤±å‡½æ•°$\\psi(y_i,f_{\\theta_j}(x_i),f_{\\theta_l}(x_i))$è¯±å¯¼æ¨¡å‹çš„å…³ç³»å‘ä¸åŒæ–¹å‘å‘å±•, ä¾‹å¦‚åŸºäºcosæˆ–KLæ•£åº¦. å®éªŒè®¾ç½®:  æ•°æ®é›†: mini-ImageNet, tiered-ImageNet, Caltech-UCSD Birds (CUB) 2002011. ensemble of ResNet18 and WideResNet28   @INPROCEEDINGS{9010380, title={Diversity With Cooperation: Ensemble Methods for Few-Shot Classification},author={Dvornik, Nikita and Mairal, Julien and Schmid, Cordelia}, booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, pages={3722-3730},\nyear={2019} }   Model Compression with Two-stage Multi-teacher Knowledge Distillation for Web Question Answering System. Yang, Ze et al. WSDM 2020 https://arxiv.org/pdf/1910.08381.pdf\n  ä¸€ç§ç”¨äºç½‘ç»œé—®ç­”ç³»ç»Ÿçš„ä¸¤é˜¶æ®µå¤šæ•™å¸ˆçŸ¥è¯†è’¸é¦(ç®€ç§° TMKD)æ–¹æ³•, é¦–å…ˆç”¨ä¸€ä¸ªé€šç”¨çš„é—®ç­”æç‚¼ä»»åŠ¡å¯¹studentè¿›è¡Œé¢„è®­ç»ƒ(è²Œä¼¼ä¹Ÿæ˜¯ä½¿ç”¨Multi-teacher), å¹¶åœ¨ä¸‹æ¸¸ä»»åŠ¡(å¦‚ Web Q\u0026A ä»»åŠ¡, MNLI, SNLI, æ¥è‡ª GLUE çš„ RTE ä»»åŠ¡)ä¸Šä½¿ç”¨Multi-Teacher KDè¿›ä¸€æ­¥å¾®è°ƒè¿™ä¸ªé¢„è®­ç»ƒçš„student. â€œearly calibrationâ€ effectç¼“è§£äº†å•ä¸ªteacheré€ æˆçš„è¿‡æ‹Ÿåˆåå·®. å®éªŒè®¾ç½®:  æ•°æ®é›† - DeepQA, CommQA-Unlabeled, CommQA-Labeled, MNLI, SNLI, QNLI, RTE. Baseline: teacher - BERT-3, BERT_{large}, BERT_{large}Ensemble; student(Traditional Distillation Model) - Bi-LSTM(1-o-1, 1_{avg}-o-1, m-o-m), BERT3(1-o-1, 1_{avg}-o-1, m-o-m), student(TMKD) - Bi-LSTM(TMKD), TMKD_{base}, TMKD_{large}(åä¸¤è€…éƒ½æ˜¯BERT-3 models).   @inproceedings{inproceedings, author = {Ze, Yang and Shou, Linjun and Gong, Ming and Lin, Wutao and Jiang, Daxin}, title = {Model Compression with Two-stage Multi-teacher Knowledge Distillation for Web Question Answering System}, publisher = {Association for Computing Machinery}, doi = {10.1145/3336191.3371792}ï¼Œ pages = {690-698}, year = {2020} }   FEED: Feature-level Ensemble for Knowledge Distillation. Park, SeongUk and Kwak, Nojun. AAAI 2020 https://openreview.net/pdf?id=BJxYEsAqY7\n  å®éªŒæ–¹æ³•å°±æ˜¯è®©studentç›´æ¥å­¦teacherçš„feature. å®éªŒè®¾ç½®: æ•°æ®é›†: CIFAR-100; é€‰å–æ¨¡å‹: student â€“ ResNet-56, ResNet-110, WRN28-10, ResNext29-16x64d; æ²¡è¯´teacheræ˜¯è°. @article{Park2019FEEDFE, title={FEED: Feature-level Ensemble for Knowledge Distillation}, author={Seonguk Park and Nojun Kwak}, journal={ECAI}, year={2019}, volume={abs/1909.10754} }   Stochasticity and Skip Connection Improve Knowledge Transfer. Lee, Kwangjin et al. ICLR 2020 https://openreview.net/pdf?id=HklA93NYwS\n  åˆ©ç”¨å•ä¸ªæ•™å¸ˆç½‘ç»œç”Ÿæˆå¤šä¸ªæ•™å¸ˆç½‘ç»œ(åŠ å…¥stochastic blockså’Œskip connections)å¹¶è®­ç»ƒå­¦ç”Ÿç½‘ç»œ, åˆ†å—å¹¶å«æœ‰skip connectionsçš„ç½‘ç»œå¯ä»¥çœ‹æˆæ ‘çŠ¶ç½‘ç»œ, ä»inputåˆ°outputæœ‰å¤šæ¡è·¯å¾„. å®éªŒè®¾ç½®: æ•°æ®é›† â€“ CIFAR-100 å’Œ tiny imagenet, å¹¶å°†è¿™ç§æ–¹æ³•åº”ç”¨åˆ°KD, AT(attention tranfer), ML. å®éªŒä¸­æ¶‰åŠåˆ°çš„teacheræœ‰ResNet 32, ResNet 110, WRN 28-10, MobileNet, WRN 40-4; æ¶‰åŠåˆ°çš„studentæœ‰VGG 13, ResNet 20, ResNet 32, WRN 40-4. @INPROCEEDINGS{9287227, author={Nguyen, Luong Trung and Lee, Kwangjin and Shim, Byonghyo}, title={Stochasticity and Skip Connection Improve Knowledge Transfer}, booktitle={2020 28th European Signal Processing Conference (EUSIPCO)}, pages={1537-1541}, year={2021} }   Hydra: Preserving Ensemble Diversity for Model Distillation. Tran, Linh et al. arXiv:2001.04694 http://www.gatsby.ucl.ac.uk/~balaji/udl2020/accepted-papers/UDL2020-paper-026.pdf\n  æ™®é€šmulti-teacher KDå¯¹teacherçš„é¢„æµ‹å€¼å–å¹³å‡, è¿™æ ·ä¼šä¸§å¤±å¤šteacherç»“æœåŒ…å«çš„ä¸ç¡®å®šæ€§ä¿¡æ¯(?), æœ¬æ–‡å°†studentæ‹†åˆ†æˆbodyå’Œå¤šä¸ªhead, æ¯ä¸ªheadå¯¹åº”ä¸€ä¸ªteacher, ä»¥ä¿ç•™å¤šteacherè¾“å‡ºçš„å¤šæ ·æ€§ å‡è®¾æœ‰Mä¸ªteacher, é¦–å…ˆè®­ç»ƒä¸€ä¸ªheadç›´è‡³å…¶æ”¶æ•›è‡³teacherçš„å¹³å‡, å†æ·»åŠ å…¶ä»–M-1ä¸ªhead, Mä¸ªheadä¸€èµ·è®­ç»ƒ, å®éªŒè¯æ˜å¦‚æœæ²¡æœ‰ç¬¬ä¸€ä¸ªheadä¼šå¾ˆéš¾æ”¶æ•›. ä½œè€…å®šä¹‰äº†ä¸€ä¸ªæ¨¡å‹ä¸ç¡®å®šæ€§, ç”±æ•°æ®ä¸ç¡®å®šæ€§å’Œæ€»ä¸ç¡®å®šæ€§ç»„æˆ(æˆ‘ä¸ç†è§£ä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªé¡ºåº). å®éªŒè®¾ç½®:  æ•°æ®é›†: a spiral toy dataset(ç”¨äºå¯è§†åŒ–å¹¶è§£é‡Šæ¨¡å‹ä¸ç¡®å®šæ€§), MNIST(æµ‹è¯•æ—¶ç”¨äº†å®ƒçš„æµ‹è¯•é›†å’ŒFashion-MNIST), CIFAR-10(æµ‹è¯•æ—¶ç”¨äº†å®ƒçš„æµ‹è¯•é›†, cyclic translated test set, 80 different corrupted test sets å’Œ SVHN). æ¨¡å‹: toy dataset - ä¸¤å±‚MLP, æ¯å±‚100ä¸ªç»“ç‚¹; MNIST - MLP; CIFAR-10 - ResNet-20 V1. åœ¨å›å½’é—®é¢˜ä¸­, æ‰€æœ‰æ•°æ®é›†å‡ä½¿ç”¨MLP.   @article{DBLP:journals/corr/abs-2001-04694, author = {Linh Tran, Bastiaan S. Veeling, Kevin Roth, Jakub Swiatkowski, Joshua V. Dillon, Jasper Snoek, Stephan Mandt, Tim Salimans, Sebastian Nowozin, Rodolphe Jenatton}, title = {Hydra: Preserving Ensemble Diversity for Model Distillation}, journal = {CoRR}, year = {2020} }   Distilling Knowledge from Ensembles of Acoustic Models for Joint CTC-Attention End-to-End Speech Recognition. Gao, Yan et al. arXiv:2005.09310 https://arxiv.org/pdf/2005.09310v1.pdf\n  @article{DBLP:journals/corr/abs-2005-09310, author = {Yan Gao, Titouan Parcollet, Nicholas D. Lane}, title = {Distilling Knowledge from Ensembles of Acoustic Models for Joint CTC-Attention End-to-End Speech Recognition}, journal = {CoRR}, year = {2020} }   Temporal Self-Ensembling Teacher for Semi-Supervised Object Detection. Chen, Cong et al. IEEE 2020 [code]\n  Dual-Teacher: Integrating Intra-domain and Inter-domain Teachers for Annotation-efficient Cardiac Segmentation. MICCAI 2020\n  Knowledge Distillation for Multi-task Learning. Li, WeiHong \u0026 Bilen, Hakan. arXiv:2007.06889 [project]\n  Adaptive Multi-Teacher Multi-level Knowledge Distillation. Liu, Yuang et al. Neurocomputing 2020 [code] https://arxiv.org/pdf/2103.04062.pdf\n  loss: $\\mathcal{L} = \\mathcal{L}{KD}+\\alpha\\mathcal{L}{angle}+\\beta\\mathcal{L}_{HT}$  $\\mathcal{L}{KD}$: å¯¹äºæ¯ä¸ªæ ·æœ¬, studentéœ€è¦èµ‹äºˆteachersçš„è¾“å‡ºä¸åŒçš„æƒé‡, studentä¸­fcä¹‹å‰çš„è¡¨ç¤ºç»è¿‡maxpoolingåå’Œæ¯ä¸ªteacherfcå‰çš„è¡¨ç¤ºåˆ†åˆ«åšç‚¹ç§¯ä½œä¸ºæƒé‡, teacherçš„åŠ æƒå’Œä½œä¸ºweighted target, å°†weighted targetä¸studentçš„soft-targeté—´çš„KLæ•£åº¦å’Œstudentè¾“å‡ºä¸groungtruthçš„äº¤å‰ç†µä½œä¸º$\\mathcal{L}{KD}$. $\\mathcal{L}{angle}$: å¯¹äºæ ·æœ¬ç»„æˆçš„ä¸‰å…ƒç»„, è®¡ç®—å®ƒä»¬çš„teacherå’Œstudentè¡¨ç¤ºçš„ç©ºé—´ç›¸å¯¹ä½ç½®, è®¡ç®—äºŒè€…çš„Huber lossä½œä¸º$\\mathcal{L}{angle}$. $\\mathcal{L}_{HT}$: è®¡ç®—teacherå’Œstudentä¸­é—´å±‚è¡¨ç¤ºçš„å·®çš„äºŒèŒƒå¼, studentçš„ä¸­é—´å±‚éœ€è¦ç»è¿‡ä¸€ä¸ªå•å±‚FitNetä½¿å…¶è§„æ¨¡ç­‰äºteacherçš„ä¸­é—´å±‚è¡¨ç¤º.   å®éªŒè®¾ç½®: æ•°æ®é›†æœ‰CIFAR-10, CIFAR-100å’ŒTiny-ImageNet.  CIFAR-10, CIFAR-100: teacherä½¿ç”¨ResNet110, VGG-19, DenseNet121, studentä¸ºResNet20; æ¯”è¾ƒä¸åŒbaseline (OKD, FitNet, RKD, AvgMKD, DML) åœ¨æ•°æ®é›†ä¸Šçš„è¡¨ç°; æ¯”è¾ƒä¸åŒbaseline(OKD, AvgMKD, DML)åœ¨teacheræ•°é‡ä¸º2,3,5æ—¶çš„è¡¨ç°. Tiny-ImageNet: teacher(ResNet110, ResNet56, ResNet32), student - ResNet20.   @article{LIU2020106, author={Yuang Liu and W. Zhang and Jijie Wang}, title = {Adaptive multi-teacher multi-level knowledge distillation}, journal = {Neurocomputing}, pages = {106-113}, year = {2020} }  ",
  "wordCount" : "6020",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Michelia-zhx"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://michelia-zhx.github.io/posts/2022-02-23-multi_teacher_knowledge_distillation-1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Michelia'Log",
    "logo": {
      "@type": "ImageObject",
      "url": "https://michelia-zhx.github.io/images/Cheese.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://michelia-zhx.github.io" accesskey="h" title="Michelia&#39;Log (Alt + H)">Michelia&#39;Log</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://michelia-zhx.github.io/" title="ğŸ§€Home">
                    <span>ğŸ§€Home</span>
                </a>
            </li>
            <li>
                <a href="https://michelia-zhx.github.io/posts" title="ğŸ¥‘Posts">
                    <span>ğŸ¥‘Posts</span>
                </a>
            </li>
            <li>
                <a href="https://michelia-zhx.github.io/archives" title="ğŸ‘Archives">
                    <span>ğŸ‘Archives</span>
                </a>
            </li>
            <li>
                <a href="https://michelia-zhx.github.io/tags" title="ğŸTags">
                    <span>ğŸTags</span>
                </a>
            </li>
            <li>
                <a href="https://michelia-zhx.github.io/about" title="ğŸ‰About">
                    <span>ğŸ‰About</span>
                </a>
            </li>
            <li>
                <a href="https://michelia-zhx.github.io/search" title="ğŸ³Search (Alt &#43; /)" accesskey=/>
                    <span>ğŸ³Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://michelia-zhx.github.io">Home</a>&nbsp;Â»&nbsp;<a href="https://michelia-zhx.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      Paper Notes - Multi-Teacher Knowledge Distillation - 1
    </h1>
    <div class="post-meta">13 min&nbsp;Â·&nbsp;Michelia-zhx

</div>
  </header> 

  <div class="post-content"><blockquote>
<p>Learning from Multiple Teacher Networks <a href="http://library.usc.edu.ph/ACM/KKD%202017/pdfs/p1285.pdf">http://library.usc.edu.ph/ACM/KKD%202017/pdfs/p1285.pdf</a></p>
</blockquote>
<ul>
<li>loss:
<ul>
<li>teachersçš„softmaxè¾“å‡ºå–å¹³å‡å’Œstudentçš„äº¤å‰ç†µ</li>
<li>ä¸­é—´å±‚è¡¨ç¤ºçš„ç›¸å¯¹ç›¸å¼‚åº¦(ä»…é€‚ç”¨äºMTKD), ä¸‰å…ƒç»„$(q_i,q_i^+,q_i^-)$, å…¶ä¸­$q$æ˜¯ä¸­é—´å±‚çš„è¾“å‡º, ååºå…³ç³»$q_i^+ &gt; q_i^-$ç”±ä¸¤è€…å’Œ$q_i$çš„è·ç¦»$d$å†³å®š, å‚æ•°$w_s$å†³å®šé€‰å–å“ªäº›å±‚. åœ¨ä¸åŒteacherä¸­, ä¸­é—´å±‚è¾“å‡ºçš„ååºå…³ç³»å¯èƒ½ä¸åŒ, å› æ­¤ç”¨æŠ•ç¥¨æ³•å†³å®šä¸­é—´å±‚è¾“å‡ºåº”å½“çš„ååºå…³ç³», è®¾è®¡å’Œstudentå¯¹åº”å±‚è¾“å‡ºçš„loss, ä»¥æ­¤é¼“åŠ±studentæ‹¥æœ‰å’Œteacherä¸­é—´å±‚ç±»ä¼¼çš„ç›¸å¯¹ç›¸ä¼¼(ç›¸å¼‚)å…³ç³».</li>
<li>studentå’Œgroudtruthçš„äº¤å‰ç†µ</li>
</ul>
</li>
<li>å®éªŒè®¾ç½®: åŸºäºCIFAR-10, CIFAR-100, MNIST, SVHNçš„å®éªŒ
<ul>
<li>CIFAR-10, æ¯”è¾ƒstudentä¸åŒå±‚æ•°å’Œå‚æ•°é‡(11/250K, 11/862K, 13/1.6M, 19/2.5M)æ—¶çš„è¡¨ç°(compression rate, acceleration rate and classification accuracy)(å’ŒFitnetsæ¯”è¾ƒ)</li>
<li>CIFAR-10, studentå‡ä¸º11å±‚, æ¯”è¾ƒå½“studentçš„å‚æ•°ä¸º250Kå’Œ862Kæ—¶, teacheræ•°é‡ä¸º1, 3, 5æ—¶, Teacher, RDL, FitNets, KDå’Œä»–ä»¬çš„å‡†ç¡®ç‡</li>
<li>CIFAR-10, CIFAR-100, æ¯”è¾ƒä¸åŒæ–¹æ³•(Teacher(5å±‚), FitNets, KD, Maxout Networks, Network in Network, Deeply-Supervised Networkså’Œæ­¤æ–¹æ³•(19å±‚))åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡</li>
<li>MNIST, æ¯”è¾ƒä¸åŒæ–¹æ³•(Teacher(4å±‚), FitNets, KD, Maxout Networks, Network in Network, Deeply-Supervised Networkså’Œæ­¤æ–¹æ³•(7å±‚))çš„å‡†ç¡®ç‡</li>
<li>SVHN, æ¯”è¾ƒä¸åŒæ–¹æ³•(Teacher(5å±‚), FitNets, KD, Maxout Networks, Network in Network, Deeply-Supervised Networkså’Œæ­¤æ–¹æ³•(19å±‚))çš„å‡†ç¡®ç‡</li>
</ul>
</li>
<li>@inproceedings{you2017learning,
author={You, Shan and Xu, Chang and Xu, Chao and Tao, Dacheng},
booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
title={Learning from multiple teacher networks},
pages={1285&ndash;1294},
year={2017}
}</li>
</ul>
<blockquote>
<p>Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data. ICLR 2017 <a href="https://openreview.net/pdf?id=HkwoSDPgg">https://openreview.net/pdf?id=HkwoSDPgg</a></p>
</blockquote>
<ul>
<li>å­¦ä¹ ç®—æ³•åº”å½“ä¿æŠ¤ç”¨æˆ·ç§äººæ•°æ®, ä½†æ¨¡å‹ä¼šè®°ä½æ•°æ®, ä¹Ÿä¼šå—åˆ°æ”»å‡»(black/white box attack).</li>
<li>å°†æ ·æœ¬åˆ†æˆnä»½, åˆ†åˆ«è®­ç»ƒteacher model, å°†è¿™äº›teachersèšåˆ:
<ul>
<li>å¦‚æœå¤§å¤šæ•°teacheræœ‰ç›¸åŒçš„è¾“å‡º, åˆ™è¾“å‡ºä¸ä¾èµ–äºåˆ†åˆ«è®­ç»ƒteacherçš„ä¸ç›¸äº¤é›†</li>
<li>å¦‚æœæœ‰æŸä¸¤ç±»ç¥¨æ•°ç›¸è¿‘, åˆ™åˆ†æ­§å¯èƒ½ä¼šæ³„éœ²ç§äººä¿¡æ¯(æˆ‘ä¸ç†è§£)</li>
<li>åœ¨æŠ•ç¥¨ä¸­å¼•å…¥éšæœºå™ªå£°</li>
</ul>
</li>
<li>studentæ˜¯åŠç›‘ç£, ä¸€éƒ¨åˆ†æ˜¯åˆ©ç”¨private dataé€šè¿‡teacherå¾—åˆ°çš„label, ä¹‹åä½¿ç”¨æ— æ ‡è®°çš„public data. åˆ©ç”¨GANè®­ç»ƒstudent, discriminatorå¢åŠ 1ç±»(m+ç”±ç”Ÿæˆå™¨ç”Ÿæˆ), è®­ç»ƒååªä½¿ç”¨discriminator.</li>
<li>å®éªŒè®¾ç½®:
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Teacher</th>
<th>Student</th>
<th>Student Public Data</th>
<th>testing Data</th>
</tr>
</thead>
<tbody>
<tr>
<td>MNIST</td>
<td>2 conv + 1 relu</td>
<td>GANS(6 fc layers)</td>
<td>test[:1000]</td>
<td>test[1000:]</td>
</tr>
<tr>
<td>SVHN</td>
<td>2 conv + 2 relu</td>
<td>GANS(7 conv + 2 NIN)</td>
<td>test[:1000]</td>
<td>test[1000:]</td>
</tr>
<tr>
<td>UCI Adult</td>
<td>RF(100 trees)</td>
<td>RF(100 trees)</td>
<td>test[:500]</td>
<td>test[500:]</td>
</tr>
<tr>
<td>UCI Diabetes</td>
<td>RF(100 trees)</td>
<td>RF(100 trees)</td>
<td>test[:500]</td>
<td>test[500:]</td>
</tr>
</tbody>
</table>
</li>
<li>@article{Papernot2017SemisupervisedKT,
title={Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data},
author={Nicolas Papernot and Mart{'i}n Abadi and {'U}lfar Erlingsson and Ian J. Goodfellow and Kunal Talwar},
journal={arXiv preprint},
pages = {},
year={2016}
}</li>
</ul>
<blockquote>
<p>Knowledge Adaptation: Teaching to Adapt. ICLR, 2017 <a href="https://openreview.net/pdf?id=rJRhzzKxl">https://openreview.net/pdf?id=rJRhzzKxl</a></p>
</blockquote>
<ul>
<li>teachersçš„domainå’Œstudent $\mathcal{D}<em>{T_i}, \mathcal{D}<em>S$ä¸å®Œå…¨ä¸€è‡´, å› æ­¤studentå¯¹teacherçš„ä¿¡ä»»åº¦å–å†³äºä¸¤è€…è¡¨ç¤ºç©ºé—´çš„ç›¸ä¼¼åº¦ $\mathcal{L} = \mathcal{H}(\sum</em>{i=1}sim(\mathcal{D}</em>{T_i}, \mathcal{D}<em>S)\cdot D</em>{T_i}, D_S)$</li>
<li>å®šä¹‰MCD, MCDè¶Šå¤§è¡¨ç¤ºè¶Šè¿œç¦»åˆ†ç±»è¾¹ç•Œ, è¾“å…¥teacherå¾—åˆ°çš„ç»“æœç½®ä¿¡åº¦è¶Šé«˜. å› æ­¤é€‰å–MCDæœ€å¤§(å³ç½®ä¿¡åº¦æœ€é«˜)çš„nä¸ªæ ·æœ¬, åœ¨teacherä¸­å¾—åˆ°çš„ç»“æœä½œä¸ºä¼ªæ ‡è®°ä»¥è®­ç»ƒstudentå¯ä»¥ä½¿æ— ç›‘ç£å­¦ä¹ çš„æ€§èƒ½å¾—åˆ°æå‡.</li>
<li>å®éªŒè®¾ç½®: åŸºäºAmazon product reviews sentiment analysis dataset. åŒ…å«Book, DVD, Electronics, Kitchenå››ç±».
<ul>
<li>æ¯”è¾ƒteacher, ç”±ä»¥ç›¸åŒç±»åˆ«æ ·æœ¬è®­ç»ƒçš„teacherè®­ç»ƒå‡ºæ¥çš„student, ç”±ä»¥æ‰€æœ‰æ ·æœ¬è®­ç»ƒçš„teacherè®­ç»ƒå‡ºæ¥çš„student, ç»“åˆä»¥ä¸Šä¸¤ç§teacherè®­ç»ƒå‡ºæ¥çš„student, ä»¥åŠè®¸å¤šå…¶ä»–æ¨¡å‹(SCL, SFA, SCL-com, SFA-com, SST, IDDIWP, DWHC, DAM, CP-MDA, SDAMS-SVM, SDAMS-Log)åœ¨å››ç§ç±»åˆ«ä¸Šçš„æ€§èƒ½.</li>
<li>æ¯”è¾ƒåˆ†åˆ«ä»¥å…¶ä¸­ä¸‰ç±»ä¸ºdomainçš„teacherè®­ç»ƒä»¥ç¬¬å››ç±»ä¸ºdomainçš„student(B$\rightarrow$D,E$\rightarrow$D,K$\rightarrow$Dä¾æ¬¡è½®æ¢)åœ¨ä¸åŒæ–¹æ³•ä¸‹çš„æ€§èƒ½</li>
</ul>
</li>
<li>@article{ruder2017knowledge,
title={Knowledge adaptation: Teaching to adapt},
author={Ruder, Sebastian and Ghaffari, Parsa and Breslin, John G},
journal={arXiv preprint arXiv:1702.02052},
pages = {},
year={2017}
}</li>
</ul>
<blockquote>
<p>Deep Model Compression: Distilling Knowledge from Noisy Teachers. Sau, Bharat Bhusan et al. arXiv:1610.09650 <a href="https://arxiv.org/pdf/1610.09650.pdf">https://arxiv.org/pdf/1610.09650.pdf</a></p>
</blockquote>
<ul>
<li>åœ¨teacherçš„è¾“å‡º(studentçš„ç›®æ ‡)ä¸ŠåŠ æ‰°åŠ¨, ç­‰ä»·äºåŸºäºå™ªå£°çš„æ­£åˆ™åŒ–. å¯ç”¨äºæ¨¡å‹å‹ç¼©.</li>
<li>å®éªŒè®¾ç½®: åŸºäºMNIST, SVHN, CIFAR-10.
<ul>
<li>MNIST: teacher &ndash; a modified network of LeNet([C5(S1P0)@20-MP2(S2)]- [C5(S1P0)@50-MP2(S2)]- FC500- FC10); student &ndash; FC800-FC800-FC10</li>
<li>SVHN: Network-in-Network([C5(S1P2)@192]- [C1(S1P0)@160]- [C1(S1P0)@96-MP3(S2)]- D0.5- [C5(S1P2)@192]- [C1(S1P0)@192]- [C1(S1P0)@192- AP3(S2)]- D0.5- [C3(S1P1)@192]- [C1(S1P0)@192]- [C1(S1P0)@10]- AP8(S1)); student: LeNet([C5(S1P2)@32-MP3(S2)]- [C5(S1P2)@64-MP3(S2)]- FC1024-FC10)</li>
<li>CIFAR-10: teacher: same as SVHN; student: a modified version of the LeNet([C5(S1P2)@64-MP2(S2)]- [C5(S1P2)@128- MP2(S2)]-FC1024-FC10).</li>
</ul>
</li>
<li>@article{sau2016deep,
title={Deep model compression: Distilling knowledge from noisy teachers},
author={Sau, Bharat Bhusan and Balasubramanian, Vineeth N},
journal={CoRR},
pages = {},
year={2016}
}</li>
</ul>
<blockquote>
<p>Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. Tarvainen, Antti and Valpola, Harri. NeurIPS 2017 <a href="https://papers.nips.cc/paper/2017/file/68053af2923e00204c3ca7c6a3150cf7-Paper.pdf">https://papers.nips.cc/paper/2017/file/68053af2923e00204c3ca7c6a3150cf7-Paper.pdf</a></p>
</blockquote>
<ul>
<li>ç®—æ³•:
<ul>
<li>æ„å»ºä¸€ä¸ªæ™®é€šçš„ç›‘ç£æ¨¡å‹;</li>
<li>copyä¸€ä»½ç›‘ç£å­¦ä¹ æ¨¡å‹, åŸæ¨¡å‹å«åšstudent, æ–°çš„å«teacher;</li>
<li>æ¯æ­¥ä½¿ç”¨åŒæ ·çš„minibatchè¾“å…¥åˆ°studentä¸teacheræ¨¡å‹ä¸­, ä½†åœ¨è¾“å…¥æ•°æ®å‰åˆ†åˆ«åŠ å…¥éšæœºå¢å¼ºæˆ–è€…å™ªéŸ³;</li>
<li>åŠ å…¥studentä¸teacherè¾“å‡ºçš„ä¸€è‡´æ€§æŸå¤±å‡½æ•°;</li>
<li>ä¼˜åŒ–å™¨åªæ›´æ–°studentçš„æƒé‡;</li>
<li>æ¯æ­¥ä¹‹å, é‡‡ç”¨studentæƒé‡çš„EMAæ›´æ–°teacheræƒé‡;</li>
</ul>
</li>
<li>æ ¸å¿ƒæ€æƒ³æ˜¯: æ¨¡å‹æ—¢å……å½“å­¦ç”Ÿ, åˆå……å½“è€å¸ˆ. ä½œä¸ºè€å¸ˆ, ç”¨æ¥äº§ç”Ÿå­¦ç”Ÿå­¦ä¹ æ—¶çš„ç›®æ ‡; ä½œä¸ºå­¦ç”Ÿ, åˆ™åˆ©ç”¨æ•™å¸ˆæ¨¡å‹äº§ç”Ÿçš„ç›®æ ‡æ¥è¿›è¡Œå­¦ä¹ . è€Œæ•™å¸ˆæ¨¡å‹çš„å‚æ•°æ˜¯ç”±å†å²ä¸Š(å‰å‡ ä¸ªstep)å‡ ä¸ªå­¦ç”Ÿæ¨¡å‹çš„å‚æ•°ç»è¿‡åŠ æƒå¹³å‡å¾—åˆ°.</li>
<li>å¯ä»¥çœ‹æˆæ˜¯ĞŸ-modelä¸­çš„ä¸¤æ¬¡è®¡ç®—ä¸­æ¨¡å‹æ¢æˆäº†ä¸¤ä¸ªä¸åŒçš„æ¨¡å‹, ä¸€ä¸ªå«teacher, ä¸€ä¸ªå«student; å¦å¤–, ä¹Ÿå¯ä»¥çœ‹æˆä½œTemporal ensemblingçš„æ”¹è¿›ç‰ˆ, åœ¨Temporal ensemblingä¸­, é‡‡ç”¨çš„æ˜¯æ¯epochçš„æŒ‡æ•°ç§»åŠ¨å¹³å‡å€¼æ¥èšåˆå†å²æ•°å†…å®¹, è€ŒMean teacheråˆ™æ˜¯åœ¨æ¯è®­ç»ƒæ­¥è¿›è¡Œå¯¹Studentçš„æƒé‡è¿›æŒ‡æ•°ç§»åŠ¨å¹³å‡.</li>
<li>å®éªŒè®¾ç½®: åŸºäºSVHNå’ŒCIFAR-10
<ul>
<li>All the methods in the comparison use a similar 13-layer ConvNet architecture.</li>
</ul>
</li>
<li>@inproceedings{10.5555/3294771.3294885,
title = {Mean Teachers Are Better Role Models: Weight-Averaged Consistency Targets Improve Semi-Supervised Deep Learning Results},
author = {Tarvainen, Antti and Valpola, Harri},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {1195â€“1204},
year = {2017}
}</li>
</ul>
<blockquote>
<p>Born-Again Neural Networks. Furlanello, Tommaso et al. ICML 2018 <a href="https://proceedings.mlr.press/v80/furlanello18a/furlanello18a.pdf">https://proceedings.mlr.press/v80/furlanello18a/furlanello18a.pdf</a></p>
</blockquote>
<ul>
<li>åŸºäºæ–°æ¨¡å‹çš„è¾“å…¥å’ŒåŸæ¨¡å‹çš„è¾“å…¥é—´çš„äº¤å‰ç†µ, ä½¿ç”¨KDé¡¹ä¿®æ”¹æ›¿ä»£å’Œæ­£åˆ™åŒ–åŸæ¥çš„loss</li>
<li>Selves Born-Again Networksé›†æˆçš„å­¦ä¹ é¡ºåº: $\mathcal{L}(f(x, \arg\min_{\theta_{k-1}}\mathcal{L}(f(x, \theta_{k-1}))),f(x,\theta_k))$, å°†ä¸Šä¸€ä¸ªstudentå­¦åˆ°çš„çŸ¥è¯†ä½œä¸ºç›‘ç£ä¿¡æ¯, æ•™å¯¼ä¸‹ä¸€ä¸ªå­¦ç”Ÿ.</li>
<li>å®éªŒè®¾ç½®:
<ul>
<li>CIFAR-10: Wide-ResNet with different depth and width (28-1, 28-2, 28-5, 28-10) and DenseNet of different depth and growth factor (112-33, 90-60, 80-80, 80-120)</li>
<li>CIFAR-100: ä¸ä¸ŠåŒ.</li>
</ul>
</li>
<li>@inproceedings{Furlanello2018BornAN,
title={Born Again Neural Networks},
author={Tommaso Furlanello and ZaKnowledge Adaptation: Teaching to Adaptchary Chase Lipton and Michael Tschannen and Laurent Itti and Anima Anandkumar},
booktitle={ICML},
year={2018}
}</li>
</ul>
<blockquote>
<p>Deep Mutual Learning. Zhang, Ying et al. CVPR 2018 <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Deep_Mutual_Learning_CVPR_2018_paper.pdf">https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Deep_Mutual_Learning_CVPR_2018_paper.pdf</a></p>
</blockquote>
<ul>
<li>ä¸¤ä¸ª(å¤šä¸ª?)studentsç›¸äº’å­¦ä¹ , å¯¹äºæ¯ä¸ªstudent, æŸå¤±ä¸ºå’Œgroundtruthçš„äº¤å‰ç†µä»¥åŠç›¸å¯¹äºå¦ä¸€ä¸ªstudentçš„softmaxè¾“å‡ºçš„KLæ•£åº¦: $\mathcal{L}<em>{\theta_1} = \mathcal{L}</em>{C_1} + D_{KL}(p_2|p_1), \theta_1\leftarrow\theta_1+\gamma_t\dfrac{\partial\mathcal{\theta_1}}{\partial\theta_1}$; $\mathcal{L}<em>{\theta_2} = \mathcal{L}</em>{C_2} + D_{KL}(p_1|p_2), \theta_2\leftarrow\theta_2+\gamma_t\dfrac{\partial\mathcal{\theta_2}}{\partial\theta_2}$</li>
<li>ä¼˜ç‚¹:
<ul>
<li>éšç€å­¦ç”Ÿç½‘ç»œçš„å¢åŠ å…¶æ•ˆç‡ä¹Ÿå¾—åˆ°æé«˜</li>
<li>å®ƒå¯ä»¥åº”ç”¨åœ¨å„ç§å„æ ·çš„ç½‘ç»œä¸­, åŒ…æ‹¬å¤§å°ä¸åŒçš„ç½‘ç»œ</li>
<li>å³ä½¿æ˜¯éå¸¸å¤§çš„ç½‘ç»œé‡‡ç”¨ç›¸äº’å­¦ä¹ ç­–ç•¥, å…¶æ€§èƒ½ä¹Ÿèƒ½å¤Ÿå¾—åˆ°æå‡</li>
</ul>
</li>
<li>å®éªŒè®¾ç½®:
<ul>
<li>æ•°æ®é›†: ImageNet, CIFAR-10, CIFAR-100, Market-1501</li>
<li>Networks:
<table>
<thead>
<tr>
<th>ResNet-32</th>
<th>MobileNet</th>
<th>InceptionV1</th>
<th>WRN-28-10</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.5M</td>
<td>3.3M</td>
<td>7.8M</td>
<td>36.5M</td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
<li>@inproceedings{8578552,
title = {Deep Mutual Learning},
author = {Y. Zhang and T. Xiang and T. M. Hospedales and H. Lu},
booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
pages = {4320-4328},
year = {2018}
}</li>
</ul>
<blockquote>
<p>Data Distillation: Towards Omni-Supervised Learning. Radosavovic, Ilija et al. CVPR 2018 <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Radosavovic_Data_Distillation_Towards_CVPR_2018_paper.pdf">https://openaccess.thecvf.com/content_cvpr_2018/papers/Radosavovic_Data_Distillation_Towards_CVPR_2018_paper.pdf</a></p>
</blockquote>
<ul>
<li>Model Distillation vs. Data Distillation: å‰è€…ensembleåŒä¸€æ ·æœ¬åœ¨ä¸åŒæ¨¡å‹çš„è¾“å‡º, åè€…ensembleåŒä¸€æ ·æœ¬ç»ä¸åŒè½¬æ¢ååœ¨åŒä¸€æ¨¡å‹çš„è¾“å‡º.</li>
<li>æ–¹æ³•:
<ul>
<li>ç”¨æ‰‹åŠ¨æ ‡æ³¨çš„æ•°æ®è®­ç»ƒæ¨¡å‹A</li>
<li>ç”¨æ¨¡å‹Aå»è®­ç»ƒæ•°æ®å¢å¹¿ (æœ¬æ–‡ä¸­ä¸º scaling and horizontal flipping) çš„æœªæ ‡æ³¨æ•°æ®</li>
<li>å°†æœªæ ‡æ³¨æ•°æ®çš„é¢„æµ‹ç»“æœé€šè¿‡ ensembling å¤šä¸ªé¢„æµ‹ç»“æœ, è½¬åŒ–ä¸º labels</li>
<li>åœ¨æ‰‹åŠ¨æ ‡æ³¨å’Œè‡ªåŠ¨æ ‡æ³¨çš„æ•°æ®é›†é‡æ–°è®­ç»ƒæ¨¡å‹</li>
</ul>
</li>
<li>å®éªŒ: åœ¨COCO Keypoint Detection, Object Detection éªŒè¯. teacherå’Œstudentéƒ½æ˜¯Mask R-CNN keypoint detection variant</li>
<li>@inproceedings{inproceedings,
title = {Data Distillation: Towards Omni-Supervised Learning},
author = {Radosavovic, Ilija and Dollar, Piotr and Girshick, Ross and Gkioxari, Georgia and He, Kaiming},
year = {2018},
doi = {10.1109/CVPR.2018.00433}
pages = {4119-4128}
}</li>
</ul>
<blockquote>
<p>Multilingual Neural Machine Translation with Knowledge Distillation. ICLR 2019 <a href="https://openreview.net/pdf?id=S1gUsoR9YX">https://openreview.net/pdf?id=S1gUsoR9YX</a></p>
</blockquote>
<ul>
<li>æ–¹æ³•å¾ˆç®€å•, å°±æ˜¯å…ˆé’ˆå¯¹æ¯å¯¹è¯­è¨€è®­ç»ƒå•ç‹¬çš„ç¿»è¯‘æ¨¡å‹ä½œä¸ºteacher, å†ç”¨multi-teacher KDè®­ç»ƒstudent, losså°±æ˜¯studentå’Œlabelçš„äº¤å‰ç†µä»¥åŠå’Œteacherçš„softmaxè¾“å‡ºçš„äº¤å‰ç†µ.</li>
<li>å®éªŒè®¾ç½®: æ•°æ®é›†: IWSLT, WMT, Ted Talk; studentå’Œteacherå‡ä½¿ç”¨Transformer
<table>
<thead>
<tr>
<th>Task</th>
<th>model hidden size $d_{model}$</th>
<th>feed-forward hidden size $d_{ff}$</th>
<th>number of layer</th>
</tr>
</thead>
<tbody>
<tr>
<td>IWSLT and Ted talk tasks</td>
<td>256</td>
<td>1024</td>
<td>2</td>
</tr>
<tr>
<td>WMT task</td>
<td>512</td>
<td>2048</td>
<td>6</td>
</tr>
</tbody>
</table>
</li>
<li>@article{Tan2019MultilingualNM,
title={Multilingual Neural Machine Translation with Knowledge Distillation},
author={Xu Tan and Yi Ren and Di He and Tao Qin and Zhou Zhao and Tie-Yan Liu},
journal={ICLR},
year={2019},
volume={abs/1902.10461}
}</li>
</ul>
<blockquote>
<p>Unifying Heterogeneous Classifiers with Distillation. Vongkulbhisal et al. CVPR 2019 <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Vongkulbhisal_Unifying_Heterogeneous_Classifiers_With_Distillation_CVPR_2019_paper.pdf">https://openaccess.thecvf.com/content_CVPR_2019/papers/Vongkulbhisal_Unifying_Heterogeneous_Classifiers_With_Distillation_CVPR_2019_paper.pdf</a></p>
</blockquote>
<ul>
<li>Nä¸ªä¸åŒçš„æ¨¡å‹$\mathcal{C} = {C_i}_{i=1}^N$å…·æœ‰ä¸åŒçš„ç»“æ„å’Œç›®æ ‡ç±»åˆ«, $C_i$è¢«è®­ç»ƒä»¥åˆ†åˆ«é¢„æµ‹$p_i(Y=l_j)$, å¹¶æ•´åˆå‡ºæ ·æœ¬åœ¨æ‰€æœ‰ç±»ä¸­çš„æ¦‚ç‡$q(Y=i_j)$. æœ€ååˆ©ç”¨$q$è®­ç»ƒstudent.</li>
<li>ä½œè€…æå‡ºäº†åŸºäºäº¤å‰ç†µæœ€å°åŒ–å’ŒçŸ©é˜µåˆ†è§£çš„æ–¹æ³•ï¼Œä»æœªæ ‡è®°çš„æ ·æœ¬ä¸­ä¼°è®¡æ‰€æœ‰ç±»åˆ«çš„soft-labels.</li>
<li>å®éªŒè®¾ç½®:
<ul>
<li>æ•°æ®é›†: ImageNet, LSUN, Places365</li>
<li>$C_i$ä»AlexNet, VGG16, ResNet18, ResNet34ä¸­éšæœºé€‰æ‹©</li>
</ul>
</li>
<li>@article{Vongkulbhisal2019UnifyingHC,
title={Unifying Heterogeneous Classifiers With Distillation},
author={Jayakorn Vongkulbhisal and Phongtharin Vinayavekhin and Marco Visentini Scarzanella},
journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2019},
pages={3170-3179}
}</li>
</ul>
<blockquote>
<p>Distilled Person Re-Identification: Towards a More Scalable System. Wu, Ancong et al. CVPR 2019 <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_Distilled_Person_Re-Identification_Towards_a_More_Scalable_System_CVPR_2019_paper.pdf">https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_Distilled_Person_Re-Identification_Towards_a_More_Scalable_System_CVPR_2019_paper.pdf</a></p>
</blockquote>
<ul>
<li>è§£å†³ä¸‰ä¸ªé—®é¢˜: é™ä½æ ‡ç­¾æˆæœ¬(å‡å°‘æ ‡ç­¾çš„éœ€æ±‚é‡); é™ä½è·¨æ•°æ®åº“æˆæœ¬(åˆ©ç”¨ä¸€äº›å…ˆéªŒçŸ¥è¯†); é™ä½æµ‹è¯•æˆæœ¬(ä½¿ç”¨è½»é‡çº§ç½‘ç»œ)</li>
<li>å‡è®¾taregt domainåŒ…å«10ä¸ªç±»çš„å›¾ç‰‡, å…ˆç”¨å¤šä¸ªä¸ªsource domainåˆ†åˆ«è®­ç»ƒå¤šä¸ªteacher model, source domainä¹‹åå¹¶ä¸ä¼šè¢«ç”¨åˆ°(åˆ©ç”¨ä¸€äº›å…ˆéªŒçŸ¥è¯†&ndash;é™ä½è·¨æ•°æ®åº“æˆæœ¬); target domainå¯ä»¥åªåŒ…å«10ä¸ªlabelled sample(10ç±»å‡æœ‰), å…¶ä½™å‡ä¸ºunlabeled sample, å¯¹äºNä¸ªunlabelled input, å®šä¹‰ç›¸ä¼¼åº¦çŸ©é˜µ$A$, å…¶ä¸­ç¬¬iè¡Œç¬¬jåˆ—è¡¨ç¤ºç¬¬iä¸ªå›¾åƒå’Œç¬¬jä¸ªå›¾åƒåœ¨åŒä¸€ä¸ªæ¨¡å‹ä¸‹è¾“å‡ºçš„ç›¸ä¼¼åº¦. ä¸ºäº†å°†çŸ¥è¯†ä»teacherè¿ç§»åˆ°student, éœ€è¦æœ€å°åŒ–teacherçš„ç›¸ä¼¼åº¦çŸ©é˜µ$A_T$å’Œstudentçš„ç›¸ä¼¼åº¦çŸ©é˜µ$A_S$çš„è·ç¦»(è¿™å¥è¯æ˜¯å­¦ä¹ single teacher).</li>
<li>åˆ†åˆ«åˆ©ç”¨teacherè®¡ç®—target domainä¸­æ¯ä¸€ä¸ªxçš„ç‰¹å¾å‘é‡, å¹¶åˆ†åˆ«è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ$A$, ä½¿ç”¨$L_{ver}$æ›´æ–°æ¯ä¸€ä¸ªè€å¸ˆæ¨¡å‹çš„æƒé‡$a$(å¯ä»¥ç†è§£ä¸ºï¼Œæƒé‡è¶Šå¤§ï¼Œè¯¥è€å¸ˆæ¨¡å‹å¯¹åº”çš„sourceå’Œtargetè¶Šç›¸ä¼¼)</li>
<li>è®¡ç®—å‡ºæ¯ä¸€ä¸ªè€å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹å¾—åˆ°çš„ç›¸ä¼¼çŸ©é˜µçš„å·®å¼‚ï¼Œå¹¶ä½¿ç”¨ä¸Šè¿°çš„æƒé‡åŠ æƒï¼Œä»è€Œå¾—åˆ°$L_{ta}$. ä½¿ç”¨$L_{ta}$å¯¹å­¦ç”Ÿæ¨¡å‹è¿›è¡Œæ›´æ–°, å¾ªç¯è®­ç»ƒ.</li>
<li>å®éªŒè®¾ç½®: æ•°æ®é›† &ndash; Market-1501, DukeMTMC. åˆ†åˆ«ä½¿ç”¨MSMT17, CUHK03, ViPER, DukeMTMC, Market-1501è®­ç»ƒ5ä¸ªteacher model$T_1, T_2, T_3, T_4, T_5$; teacher &ndash; an advanced Re-ID model PCB, student &ndash; a lightweight mod- el MobileNetV2.</li>
<li>@InProceedings{Wu_2019_CVPR,
author = {Wu, Ancong and Zheng, Wei-Shi and Guo, Xiaowei and Lai, Jian-Huang},
title = {Distilled Person Re-Identification: Towards a More Scalable System},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}</li>
</ul>
<blockquote>
<p>Diversity with Cooperation: Ensemble Methods for Few-Shot Classification. Dvornik, Nikita et al. ICCV 2019 <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Dvornik_Diversity_With_Cooperation_Ensemble_Methods_for_Few-Shot_Classification_ICCV_2019_paper.pdf">https://openaccess.thecvf.com/content_ICCV_2019/papers/Dvornik_Diversity_With_Cooperation_Ensemble_Methods_for_Few-Shot_Classification_ICCV_2019_paper.pdf</a></p>
</blockquote>
<ul>
<li>meta learning &ndash; learning to learn</li>
<li>æ¨¡å‹é—´çš„å…³ç³»æœ‰ä¸‰ç§ - åˆä½œ(é¢„æµ‹çš„ç»“æœæ— è®ºæ˜¯å±äºæ­£ç¡®ç»“æœçš„æ¦‚ç‡è¿˜æ˜¯å±äºé”™è¯¯ç»“æœçš„æ¦‚ç‡éƒ½æ˜¯æ¯”è¾ƒä¸€è‡´çš„), ç‹¬ç«‹(ä¸¤ä¸ªæ¨¡å‹é¢„æµ‹çš„ç»“æœä¹‹é—´ä¸å­˜åœ¨æ˜æ˜¾çš„å…³ç³»), å¤šæ ·æ€§(é™¤äº†æ­£ç¡®ç»“æœï¼Œé¢„æµ‹ä¸ºå…¶ä»–ç»“æœçš„æ¦‚ç‡å·®å¼‚æ˜æ˜¾).</li>
<li>æ–‡ç« é€šè¿‡å‡ºäº†äº¤å‰ç†µæŸå¤±å¤–è®¾è®¡ä¸åŒçš„æŸå¤±å‡½æ•°$\psi(y_i,f_{\theta_j}(x_i),f_{\theta_l}(x_i))$è¯±å¯¼æ¨¡å‹çš„å…³ç³»å‘ä¸åŒæ–¹å‘å‘å±•, ä¾‹å¦‚åŸºäºcosæˆ–KLæ•£åº¦.</li>
<li>å®éªŒè®¾ç½®:
<ul>
<li>æ•°æ®é›†: mini-ImageNet, tiered-ImageNet, Caltech-UCSD Birds (CUB) 2002011.</li>
<li>ensemble of ResNet18 and WideResNet28</li>
</ul>
</li>
<li>@INPROCEEDINGS{9010380,
title={Diversity With Cooperation: Ensemble Methods for Few-Shot Classification},author={Dvornik, Nikita and Mairal, Julien and Schmid, Cordelia},
booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
pages={3722-3730},<br>
year={2019}
}</li>
</ul>
<blockquote>
<p>Model Compression with Two-stage Multi-teacher Knowledge Distillation for Web Question Answering System. Yang, Ze et al. WSDM 2020 <a href="https://arxiv.org/pdf/1910.08381.pdf">https://arxiv.org/pdf/1910.08381.pdf</a></p>
</blockquote>
<ul>
<li>ä¸€ç§ç”¨äºç½‘ç»œé—®ç­”ç³»ç»Ÿçš„ä¸¤é˜¶æ®µå¤šæ•™å¸ˆçŸ¥è¯†è’¸é¦(ç®€ç§° TMKD)æ–¹æ³•, é¦–å…ˆç”¨ä¸€ä¸ªé€šç”¨çš„é—®ç­”æç‚¼ä»»åŠ¡å¯¹studentè¿›è¡Œé¢„è®­ç»ƒ(è²Œä¼¼ä¹Ÿæ˜¯ä½¿ç”¨Multi-teacher), å¹¶åœ¨ä¸‹æ¸¸ä»»åŠ¡(å¦‚ Web Q&amp;A ä»»åŠ¡, MNLI, SNLI, æ¥è‡ª GLUE çš„ RTE ä»»åŠ¡)ä¸Šä½¿ç”¨Multi-Teacher KDè¿›ä¸€æ­¥å¾®è°ƒè¿™ä¸ªé¢„è®­ç»ƒçš„student.</li>
<li>â€œearly calibrationâ€ effectç¼“è§£äº†å•ä¸ªteacheré€ æˆçš„è¿‡æ‹Ÿåˆåå·®.</li>
<li>å®éªŒè®¾ç½®:
<ul>
<li>æ•°æ®é›† - DeepQA, CommQA-Unlabeled, CommQA-Labeled, MNLI, SNLI, QNLI, RTE.</li>
<li>Baseline: teacher - BERT-3, BERT_{large}, BERT_{large}Ensemble; student(Traditional Distillation Model) - Bi-LSTM(1-o-1, 1_{avg}-o-1, m-o-m), BERT3(1-o-1, 1_{avg}-o-1, m-o-m), student(TMKD) - Bi-LSTM(TMKD), TMKD_{base}, TMKD_{large}(åä¸¤è€…éƒ½æ˜¯BERT-3 models).</li>
</ul>
</li>
<li>@inproceedings{inproceedings,
author = {Ze, Yang and Shou, Linjun and Gong, Ming and Lin, Wutao and Jiang, Daxin},
title = {Model Compression with Two-stage Multi-teacher Knowledge Distillation for Web Question Answering System},
publisher = {Association for Computing Machinery},
doi = {10.1145/3336191.3371792}ï¼Œ
pages = {690-698},
year = {2020}
}</li>
</ul>
<blockquote>
<p>FEED: Feature-level Ensemble for Knowledge Distillation. Park, SeongUk and Kwak, Nojun. AAAI 2020 <a href="https://openreview.net/pdf?id=BJxYEsAqY7">https://openreview.net/pdf?id=BJxYEsAqY7</a></p>
</blockquote>
<ul>
<li>å®éªŒæ–¹æ³•å°±æ˜¯è®©studentç›´æ¥å­¦teacherçš„feature.</li>
<li>å®éªŒè®¾ç½®: æ•°æ®é›†: CIFAR-100; é€‰å–æ¨¡å‹: student &ndash; ResNet-56, ResNet-110, WRN28-10, ResNext29-16x64d; æ²¡è¯´teacheræ˜¯è°.</li>
<li>@article{Park2019FEEDFE,
title={FEED: Feature-level Ensemble for Knowledge Distillation},
author={Seonguk Park and Nojun Kwak},
journal={ECAI},
year={2019},
volume={abs/1909.10754}
}</li>
</ul>
<blockquote>
<p>Stochasticity and Skip Connection Improve Knowledge Transfer. Lee, Kwangjin et al. ICLR 2020 <a href="https://openreview.net/pdf?id=HklA93NYwS">https://openreview.net/pdf?id=HklA93NYwS</a></p>
</blockquote>
<ul>
<li>åˆ©ç”¨å•ä¸ªæ•™å¸ˆç½‘ç»œç”Ÿæˆå¤šä¸ªæ•™å¸ˆç½‘ç»œ(åŠ å…¥stochastic blockså’Œskip connections)å¹¶è®­ç»ƒå­¦ç”Ÿç½‘ç»œ, åˆ†å—å¹¶å«æœ‰skip connectionsçš„ç½‘ç»œå¯ä»¥çœ‹æˆæ ‘çŠ¶ç½‘ç»œ, ä»inputåˆ°outputæœ‰å¤šæ¡è·¯å¾„.</li>
<li>å®éªŒè®¾ç½®: æ•°æ®é›† &ndash; CIFAR-100 å’Œ tiny imagenet, å¹¶å°†è¿™ç§æ–¹æ³•åº”ç”¨åˆ°KD, AT(attention tranfer), ML. å®éªŒä¸­æ¶‰åŠåˆ°çš„teacheræœ‰ResNet 32, ResNet 110, WRN 28-10, MobileNet, WRN 40-4; æ¶‰åŠåˆ°çš„studentæœ‰VGG 13, ResNet 20, ResNet 32, WRN 40-4.</li>
<li>@INPROCEEDINGS{9287227,
author={Nguyen, Luong Trung and Lee, Kwangjin and Shim, Byonghyo},
title={Stochasticity and Skip Connection Improve Knowledge Transfer},
booktitle={2020 28th European Signal Processing Conference (EUSIPCO)},
pages={1537-1541},
year={2021}
}</li>
</ul>
<blockquote>
<p>Hydra: Preserving Ensemble Diversity for Model Distillation. Tran, Linh et al. arXiv:2001.04694 <a href="http://www.gatsby.ucl.ac.uk/~balaji/udl2020/accepted-papers/UDL2020-paper-026.pdf">http://www.gatsby.ucl.ac.uk/~balaji/udl2020/accepted-papers/UDL2020-paper-026.pdf</a></p>
</blockquote>
<ul>
<li>æ™®é€šmulti-teacher KDå¯¹teacherçš„é¢„æµ‹å€¼å–å¹³å‡, è¿™æ ·ä¼šä¸§å¤±å¤šteacherç»“æœåŒ…å«çš„ä¸ç¡®å®šæ€§ä¿¡æ¯(?), æœ¬æ–‡å°†studentæ‹†åˆ†æˆbodyå’Œå¤šä¸ªhead, æ¯ä¸ªheadå¯¹åº”ä¸€ä¸ªteacher, ä»¥ä¿ç•™å¤šteacherè¾“å‡ºçš„å¤šæ ·æ€§</li>
<li>å‡è®¾æœ‰Mä¸ªteacher, é¦–å…ˆè®­ç»ƒä¸€ä¸ªheadç›´è‡³å…¶æ”¶æ•›è‡³teacherçš„å¹³å‡, å†æ·»åŠ å…¶ä»–M-1ä¸ªhead, Mä¸ªheadä¸€èµ·è®­ç»ƒ, å®éªŒè¯æ˜å¦‚æœæ²¡æœ‰ç¬¬ä¸€ä¸ªheadä¼šå¾ˆéš¾æ”¶æ•›. ä½œè€…å®šä¹‰äº†ä¸€ä¸ªæ¨¡å‹ä¸ç¡®å®šæ€§, ç”±æ•°æ®ä¸ç¡®å®šæ€§å’Œæ€»ä¸ç¡®å®šæ€§ç»„æˆ(æˆ‘ä¸ç†è§£ä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªé¡ºåº).</li>
<li>å®éªŒè®¾ç½®:
<ul>
<li>æ•°æ®é›†: a spiral toy dataset(ç”¨äºå¯è§†åŒ–å¹¶è§£é‡Šæ¨¡å‹ä¸ç¡®å®šæ€§), MNIST(æµ‹è¯•æ—¶ç”¨äº†å®ƒçš„æµ‹è¯•é›†å’ŒFashion-MNIST), CIFAR-10(æµ‹è¯•æ—¶ç”¨äº†å®ƒçš„æµ‹è¯•é›†, cyclic translated test set, 80 different corrupted test sets å’Œ SVHN).</li>
<li>æ¨¡å‹: toy dataset - ä¸¤å±‚MLP, æ¯å±‚100ä¸ªç»“ç‚¹; MNIST - MLP; CIFAR-10 - ResNet-20 V1. åœ¨å›å½’é—®é¢˜ä¸­, æ‰€æœ‰æ•°æ®é›†å‡ä½¿ç”¨MLP.</li>
</ul>
</li>
<li>@article{DBLP:journals/corr/abs-2001-04694,
author = {Linh Tran, Bastiaan S. Veeling, Kevin Roth, Jakub Swiatkowski, Joshua V. Dillon, Jasper Snoek, Stephan Mandt, Tim Salimans, Sebastian Nowozin, Rodolphe Jenatton},
title = {Hydra: Preserving Ensemble Diversity for Model Distillation},
journal = {CoRR},
year = {2020}
}</li>
</ul>
<blockquote>
<p>Distilling Knowledge from Ensembles of Acoustic Models for Joint CTC-Attention End-to-End Speech Recognition. Gao, Yan et al. arXiv:2005.09310 <a href="https://arxiv.org/pdf/2005.09310v1.pdf">https://arxiv.org/pdf/2005.09310v1.pdf</a></p>
</blockquote>
<ul>
<li>@article{DBLP:journals/corr/abs-2005-09310,
author = {Yan Gao, Titouan Parcollet, Nicholas D. Lane},
title = {Distilling Knowledge from Ensembles of Acoustic Models for Joint CTC-Attention End-to-End Speech Recognition},
journal = {CoRR},
year = {2020}
}</li>
</ul>
<blockquote>
<p>Temporal Self-Ensembling Teacher for Semi-Supervised Object Detection. Chen, Cong et al. IEEE 2020 [code]</p>
</blockquote>
<blockquote>
<p>Dual-Teacher: Integrating Intra-domain and Inter-domain Teachers for Annotation-efficient Cardiac Segmentation. MICCAI 2020</p>
</blockquote>
<blockquote>
<p>Knowledge Distillation for Multi-task Learning. Li, WeiHong &amp; Bilen, Hakan. arXiv:2007.06889 [project]</p>
</blockquote>
<blockquote>
<p>Adaptive Multi-Teacher Multi-level Knowledge Distillation. Liu, Yuang et al. Neurocomputing 2020 [code] <a href="https://arxiv.org/pdf/2103.04062.pdf">https://arxiv.org/pdf/2103.04062.pdf</a></p>
</blockquote>
<ul>
<li>loss: $\mathcal{L} = \mathcal{L}<em>{KD}+\alpha\mathcal{L}</em>{angle}+\beta\mathcal{L}_{HT}$
<ul>
<li>$\mathcal{L}<em>{KD}$: å¯¹äºæ¯ä¸ªæ ·æœ¬, studentéœ€è¦èµ‹äºˆteachersçš„è¾“å‡ºä¸åŒçš„æƒé‡, studentä¸­fcä¹‹å‰çš„è¡¨ç¤ºç»è¿‡maxpoolingåå’Œæ¯ä¸ªteacherfcå‰çš„è¡¨ç¤ºåˆ†åˆ«åšç‚¹ç§¯ä½œä¸ºæƒé‡, teacherçš„åŠ æƒå’Œä½œä¸ºweighted target, å°†weighted targetä¸studentçš„soft-targeté—´çš„KLæ•£åº¦å’Œstudentè¾“å‡ºä¸groungtruthçš„äº¤å‰ç†µä½œä¸º$\mathcal{L}</em>{KD}$.</li>
<li>$\mathcal{L}<em>{angle}$: å¯¹äºæ ·æœ¬ç»„æˆçš„ä¸‰å…ƒç»„, è®¡ç®—å®ƒä»¬çš„teacherå’Œstudentè¡¨ç¤ºçš„ç©ºé—´ç›¸å¯¹ä½ç½®, è®¡ç®—äºŒè€…çš„Huber lossä½œä¸º$\mathcal{L}</em>{angle}$.</li>
<li>$\mathcal{L}_{HT}$: è®¡ç®—teacherå’Œstudentä¸­é—´å±‚è¡¨ç¤ºçš„å·®çš„äºŒèŒƒå¼, studentçš„ä¸­é—´å±‚éœ€è¦ç»è¿‡ä¸€ä¸ªå•å±‚FitNetä½¿å…¶è§„æ¨¡ç­‰äºteacherçš„ä¸­é—´å±‚è¡¨ç¤º.</li>
</ul>
</li>
<li>å®éªŒè®¾ç½®: æ•°æ®é›†æœ‰CIFAR-10, CIFAR-100å’ŒTiny-ImageNet.
<ul>
<li>CIFAR-10, CIFAR-100: teacherä½¿ç”¨ResNet110, VGG-19, DenseNet121, studentä¸ºResNet20; æ¯”è¾ƒä¸åŒbaseline (OKD, FitNet, RKD, AvgMKD, DML) åœ¨æ•°æ®é›†ä¸Šçš„è¡¨ç°; æ¯”è¾ƒä¸åŒbaseline(OKD, AvgMKD, DML)åœ¨teacheræ•°é‡ä¸º2,3,5æ—¶çš„è¡¨ç°.</li>
<li>Tiny-ImageNet: teacher(ResNet110, ResNet56, ResNet32), student - ResNet20.</li>
</ul>
</li>
<li>@article{LIU2020106,
author={Yuang Liu and W. Zhang and Jijie Wang},
title = {Adaptive multi-teacher multi-level knowledge distillation},
journal = {Neurocomputing},
pages = {106-113},
year = {2020}
}</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://michelia-zhx.github.io/tags/knowledge-distillation/">Knowledge Distillation</a></li>
      <li><a href="https://michelia-zhx.github.io/tags/paper-notes/">Paper Notes</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://michelia-zhx.github.io/posts/2021-08-31-active_learning/">
    <span class="title">Â« Prev Page</span>
    <br>
    <span>Paper Notes - Active Learning</span>
  </a>
  <a class="next" href="https://michelia-zhx.github.io/posts/2022-02-24-multi_teacher_knowledge_distillation-2/">
    <span class="title">Next Page Â»</span>
    <br>
    <span>Paper Notes - Multi-Teacher Knowledge Distillation - 2</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper Notes - Multi-Teacher Knowledge Distillation - 1 on twitter"
        href="https://twitter.com/intent/tweet/?text=Paper%20Notes%20-%20Multi-Teacher%20Knowledge%20Distillation%20-%201&amp;url=https%3a%2f%2fmichelia-zhx.github.io%2fposts%2f2022-02-23-multi_teacher_knowledge_distillation-1%2f&amp;hashtags=KnowledgeDistillation%2cPaperNotes">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper Notes - Multi-Teacher Knowledge Distillation - 1 on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fmichelia-zhx.github.io%2fposts%2f2022-02-23-multi_teacher_knowledge_distillation-1%2f&amp;title=Paper%20Notes%20-%20Multi-Teacher%20Knowledge%20Distillation%20-%201&amp;summary=Paper%20Notes%20-%20Multi-Teacher%20Knowledge%20Distillation%20-%201&amp;source=https%3a%2f%2fmichelia-zhx.github.io%2fposts%2f2022-02-23-multi_teacher_knowledge_distillation-1%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper Notes - Multi-Teacher Knowledge Distillation - 1 on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fmichelia-zhx.github.io%2fposts%2f2022-02-23-multi_teacher_knowledge_distillation-1%2f&title=Paper%20Notes%20-%20Multi-Teacher%20Knowledge%20Distillation%20-%201">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper Notes - Multi-Teacher Knowledge Distillation - 1 on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fmichelia-zhx.github.io%2fposts%2f2022-02-23-multi_teacher_knowledge_distillation-1%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper Notes - Multi-Teacher Knowledge Distillation - 1 on whatsapp"
        href="https://api.whatsapp.com/send?text=Paper%20Notes%20-%20Multi-Teacher%20Knowledge%20Distillation%20-%201%20-%20https%3a%2f%2fmichelia-zhx.github.io%2fposts%2f2022-02-23-multi_teacher_knowledge_distillation-1%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper Notes - Multi-Teacher Knowledge Distillation - 1 on telegram"
        href="https://telegram.me/share/url?text=Paper%20Notes%20-%20Multi-Teacher%20Knowledge%20Distillation%20-%201&amp;url=https%3a%2f%2fmichelia-zhx.github.io%2fposts%2f2022-02-23-multi_teacher_knowledge_distillation-1%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://michelia-zhx.github.io">Michelia&#39;Log</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>


<script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
</body>

</html>
